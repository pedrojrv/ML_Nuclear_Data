<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>nucml.datasets API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>nucml.datasets</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
from pathlib import Path
from joblib import dump, load
import logging
import glob
import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import nucml.config as config

logging.basicConfig(level=logging.INFO)

import nucml.general_utilities as gen_utils 
import nucml.processing as nuc_proc 

ame_dir_path = config.ame_dir_path
evaluations_path = config.evaluations_path
ensdf_path = config.ensdf_path


exfor_elements = gen_utils.load_obj(os.path.join(os.path.dirname(__file__), &#39;objects/exfor_elements_list.pkl&#39;))
# element_info = gen_utils.load_obj(os.path.join(os.path.dirname(__file__), &#39;objects/element_basic_dict.pkl&#39;))
dtype_exfor = gen_utils.load_obj(os.path.join(os.path.dirname(__file__), &#39;objects/EXFOR_AME_dtypes.pkl&#39;))


###############################################################################
####################### ATOMIC MASS EVALUATION ################################
###############################################################################
def load_ame(natural=False, imputed_nan=False, file=&#34;merged&#34;):    
    &#34;&#34;&#34;Loads the Atomic Mass Evaluation 2016 data generated by NucML using the parsing utilities.

    Args:
        natural (bool): if True, the AME data will be loaded along with rows representing natural data. Only
            applicable when file=&#39;merged&#39;.
        nan (bool): If True, the original AME data will be loaded. If False, then the linearly imputed data 
            is loaded. Only applicable when file=&#39;merged&#39;
        file (str): Dataset to extract. Options include &#39;merged&#39;, &#39;mass16&#39;, &#39;rct1&#39;, and &#39;rct2&#39;.
    Returns:
        ame (DataFrame): a pandas dataframe cantaining the queried AME data.

    &#34;&#34;&#34;
    directory = ame_dir_path
    if file.lower() == &#34;merged&#34;:
        if natural:
            if imputed_nan:
                ame_file_path = os.path.join(directory, &#34;AME_Natural_Properties_no_NaN.csv&#34;)
            else:
                ame_file_path = os.path.join(directory, &#34;AME_Natural_Properties_w_NaN.csv&#34;)
        else:
            if imputed_nan:
                ame_file_path = os.path.join(directory, &#34;AME_all_merged_no_NaN.csv&#34;)
            else:
                ame_file_path = os.path.join(directory, &#34;AME_all_merged.csv&#34;)

        logging.info(&#34;AME: Reading and loading Atomic Mass Evaluation files from: \n {}&#34;.format(ame_file_path))
        ame = pd.read_csv(ame_file_path)
        ame[[&#34;N&#34;, &#34;Z&#34;, &#34;A&#34;]] = ame[[&#34;N&#34;, &#34;Z&#34;, &#34;A&#34;]].astype(int)
    elif file.lower() in [&#34;mass16&#34;, &#34;rct1&#34;, &#34;rct2&#34;]:
        ame_file_path = os.path.join(ame_dir_path, &#34;AME_{}.csv&#34;.format(file))
        logging.info(&#34;AME: Reading and loading the Atomic Mass Evaluation file from: \n {}&#34;.format(ame_file_path))
        ame = pd.read_csv(ame_file_path)
    return ame


###############################################################################
####################### EVALUATED LIBRARIES ###################################
###############################################################################
def load_evaluation(ELAAA, MT, mode=&#34;neutrons&#34;, library=&#34;endfb8.0&#34;, mev_to_ev=True, mb_to_b=True, log=True, drop_u=True):
    &#34;&#34;&#34;Reads an evaluation file for a specific element and reaction channel. It is important
    to inspect the returned data since it queries an external database which extracted data from ENDF 
    using a particular script. It has been found that some particular reactions are not included.

    Args:
        ELAAA (str): element to query. The string must start with the element followed by the mass number (i.e. U233, Cl35) 
        MT (int): reaction channel to query. Must be an integer (i.e. 1, 2, 3)
        mode (str): projectile of the reaction of interest. Only &#34;neutrons&#34; and &#34;protons&#34; is allowed for now.
        library (str): evaluation library to query. Allowed options include endfb8.0, jendl4.0, jeff3.3, and tendl.2019.
        mev_to_ev (bool): if True, it converts the energy from MeV to eV.
        mb_to_b (bool): if True, it converts the cross sections from millibarns to barns.
        log (bool): if True, it applies the log10 to both the Energy and the Cross Section.
        drop_u (bool): sometimes, evaluation files contain uncertainty values. If True, these features are removed.
    Returns:
        evaluation (DataFrame): pandas DataFrame containing the ENDF datapoints.
    &#34;&#34;&#34;
    MT = gen_utils.parse_mt(MT)
    ELAAA = gen_utils.parse_elaaa(ELAAA, parse_for=&#39;endf&#39;)

    if mode == &#34;protons&#34;:
        projectile = &#39;p&#39;
    elif mode == &#34;neutrons&#34;:
        projectile = &#39;n&#39;

    path = os.path.join(evaluations_path, &#39;{}/{}/{}/tables/xs/{}-{}-{}.{}&#39;.format(mode, ELAAA, library, projectile, ELAAA, MT, library))    

    file = Path(path)
    if file.is_file():
        logging.info(&#34;EVALUATION: Extracting data from {}&#34;.format(path))
        evaluation = pd.read_csv(path, skiprows=5, header=None, names=[&#34;Energy&#34;, &#34;Data&#34;, &#34;dDataLow&#34;, &#34;dDataUpp&#34;], delim_whitespace=True)
        if mev_to_ev:
            logging.info(&#34;EVALUATION: Converting MeV to eV...&#34;)
            evaluation[&#34;Energy&#34;] = evaluation[&#34;Energy&#34;]*1E6
        if mb_to_b:
            logging.info(&#34;EVALUATION: Converting mb to b...&#34;)
            evaluation[&#34;Data&#34;] = evaluation[&#34;Data&#34;]*0.001
        if log:
            evaluation[&#34;Energy&#34;] = np.log10(evaluation[&#34;Energy&#34;])
            evaluation[&#34;Data&#34;] = np.log10(evaluation[&#34;Data&#34;])
            evaluation[&#34;dDataLow&#34;] = np.log10(evaluation[&#34;dDataLow&#34;])
            evaluation[&#34;dDataUpp&#34;] = np.log10(evaluation[&#34;dDataUpp&#34;])
        if drop_u:
            if &#34;dData&#34; in list(evaluation.columns):
                evaluation = evaluation.drop(columns=[&#34;dDataLow&#34;])
            if &#34;dData2&#34; in list(evaluation.columns):
                evaluation = evaluation.drop(columns=[&#34;dDataUpp&#34;])
            if &#34;dDataLow&#34; in list(evaluation.columns):
                evaluation = evaluation.drop(columns=[&#34;dDataLow&#34;])
            if &#34;dDataUpp&#34; in list(evaluation.columns):
                evaluation = evaluation.drop(columns=[&#34;dDataUpp&#34;])
        logging.info(&#34;EVALUATION: Finished. ENDF data contains {} datapoints.&#34;.format(evaluation.shape[0]))
        return evaluation
    else:
        raise FileNotFoundError(&#39;Evaluation file does not exists at {}&#39;.format(path))



        
###############################################################################
####################### ENSDF LIBRARIES #######################################
###############################################################################

def load_ensdf_headers():
    &#34;&#34;&#34;Loads ENSDF headers from RIPL .dat files.

    The features include &#34;Element_w_A&#34;, &#34;A&#34;, &#34;Z&#34;, &#34;Number_of_Levels&#34;, &#34;Number_of_Gammas&#34;, &#34;N_max&#34;, &#34;N_c&#34;, &#34;Sn&#34;, &#34;Sp&#34;

    Returns:
        DataFrame
    &#34;&#34;&#34;    
    csv_file = os.path.join(ensdf_path, &#34;CSV_Files/all_ensdf_headers_formatted.csv&#34;)
    ensdf_index_col = [&#34;Element_w_A&#34;, &#34;A&#34;, &#34;Z&#34;, &#34;Number_of_Levels&#34;, &#34;Number_of_Gammas&#34;, &#34;N_max&#34;, &#34;N_c&#34;, &#34;Sn&#34;, &#34;Sp&#34;]
    ensdf_index = pd.read_csv(csv_file, names=ensdf_index_col, sep=&#34;|&#34;)
    return ensdf_index

def load_ensdf_isotopic(ELAAA, filetype=&#34;levels&#34;):
    &#34;&#34;&#34;Loads level or gamma records for a given isotope.

    Args:
        ELAAA (str): isotope to query (i.e. u235, cl35, 239Pu)
        filetype (str, optional): specifies if level or gamma records are to be extracted. Options 
            include &#34;levels&#34; and &#34;gammas&#34;. Defaults to &#34;levels&#34;.

    Returns:
        DataFrame
    &#34;&#34;&#34;    
    ELAAA = gen_utils.parse_elaaa(ELAAA, parse_for=&#34;ENSDF&#34;)
    file = os.path.join(ensdf_path, &#34;Elemental_ENSDF/Elemental_ENSDF_no_Header_F/{}.txt&#34;.format(ELAAA))
    elemental = pd.read_csv(file, header=None, sep=&#34;|&#34;)
    elemental[0] = pd.to_numeric(elemental[0].astype(str).str.strip())

    if filetype.lower() == &#34;levels&#34;:
        elemental_level_records = elemental[elemental[0].notna()]
        elemental_level_records = elemental_level_records.reset_index(drop=True).drop(columns=[7,8])
        elemental_level_records.columns = [&#34;Level_Number&#34;, &#34;Energy&#34;, &#34;Spin&#34;, &#34;Parity&#34;, &#34;Half_Life&#34;, &#34;Gammas&#34;, &#34;Flag&#34;, &#34;ENSDF_Spin&#34;, &#34;Num_Decay_Modes&#34;, &#34;Decay_Info&#34;]
        elemental_level_records.Num_Decay_Modes = elemental_level_records.Num_Decay_Modes.replace(&#34;0+#&#34;, -1)

        for col in elemental_level_records.columns:
            elemental_level_records[col] = elemental_level_records[col].astype(str).str.strip()

        for col in elemental_level_records.columns:
            if col not in [&#34;Flag&#34;, &#34;ENSDF_Spin&#34;, &#34;Decay_Info&#34;]:
                elemental_level_records[col] = pd.to_numeric(elemental_level_records[col])

        return elemental_level_records
    elif filetype.lower() == &#34;gammas&#34;:
        elemental[0] = elemental[0].fillna(method=&#39;ffill&#39;)
        elemental[1] = pd.to_numeric(elemental[1].str.strip())
        elemental_gamma_records = elemental[~elemental[1].notna()]
        new_columns = elemental_gamma_records[11].str.split(expand=True)
        elemental_gamma_records = elemental_gamma_records.drop(columns=[1, 2, 3, 4, 5, 6, 10, 11])
        elemental_gamma_records = pd.concat([elemental_gamma_records, new_columns], axis=1)
        elemental_gamma_records.columns = [&#34;Level_Record&#34;, &#34;Final_State&#34;, &#34;Energy&#34;, &#34;Gamma_Decay_Prob&#34;, &#34;Electromag_Decay_Prob&#34;, &#34;ICC&#34;]
        for col in elemental_gamma_records.columns:
            elemental_gamma_records[col] = pd.to_numeric(elemental_gamma_records[col])
        return elemental_gamma_records

def load_ensdf_ground_states():
    &#34;&#34;&#34;Loads the ENSDF file. Only ground state information.

    Returns:
        DataFrame
    &#34;&#34;&#34;    
    df = pd.read_csv(os.path.join(ensdf_path, &#34;CSV_Files/ensdf_stable_state_formatted.csv&#34;), header=None, sep=&#39;|&#39;)
    df = df.drop(columns=[1, 2, 6])
    df.columns = [&#34;Element_w_A&#34;, &#34;Spin&#34;, &#34;Parity&#34;, &#34;Half_Life&#34;, &#34;Flag&#34;, &#34;ENSDF_Spin&#34;, &#34;Num_Decay_Modes&#34;, &#34;Modifier&#34;, &#34;Decay_Info&#34;]
    for col in df.columns:
        df[col] = df[col].astype(str).str.strip()
    df.Num_Decay_Modes = df.Num_Decay_Modes.replace(&#34;0+#&#34;, -1)
    for col in df.columns:
        if col not in [&#34;Element_w_A&#34;, &#34;Flag&#34;, &#34;ENSDF_Spin&#34;, &#34;Modifier&#34;, &#34;Decay_Info&#34;]:
            df[col] = pd.to_numeric(df[col])
    return df

def load_ripl_parameters():
    &#34;&#34;&#34;Loads the RIPL level cut-off parameters file.

    Returns:
        DataFrame: pandas DataFrame 
    &#34;&#34;&#34;    
    ripl_params = pd.read_csv(os.path.join(ensdf_path, &#34;CSV_Files/ripl_cut_off_energies.csv&#34;))
    return ripl_params

def load_ensdf(cutoff=False, append_ame=False):
    &#34;&#34;&#34;Loads the Evalauted Nuclear Structure Data File generated using NucML.

    Args:
        cutoff (bool, optional): If True, the RIPL cutoff ENSDF file is loaded. Defaults to False.

    Returns:
        DataFrame: if num=True, the function returns 6 variables. 
    &#34;&#34;&#34;    
    if cutoff:
        datapath = os.path.join(ensdf_path, &#34;CSV_Files/ensdf_cutoff.csv&#34;)
    else:
        datapath = os.path.join(ensdf_path, &#34;CSV_Files/ensdf.csv&#34;)

    logging.info(&#34;Reading data from {}&#34;.format(datapath))
    df = pd.read_csv(datapath)
    df[&#34;Level_Number&#34;] = df[&#34;Level_Number&#34;].astype(int)
    if append_ame:
        ame = load_ame(imputed_nan=True)
        df = pd.merge(df, ame, on=&#39;Element_w_A&#39;)
    return df


def load_ensdf_ml(log_sqrt=False, log=False, append_ame=False, basic=-1, num=False, frac=0.3, scaling_type=&#34;std&#34;, scaler_dir=None):
    path = &#39;../../ENSDF/CSV_Files/Level_Density&#39; # use your path
    all_files = glob.glob(path + &#34;/*.csv&#34;)

    if len(all_files) != 0:

        li = []

        for filename in all_files:
            df = pd.read_csv(filename, index_col=None, header=0)
            li.append(df)

        df = pd.concat(li, axis=0, ignore_index=True)

        df[&#34;Level_Number&#34;] = df[&#34;Level_Number&#34;].astype(int)
        df[[&#34;Target_Element_w_A&#34;]] = df[[&#34;Target_Element_w_A&#34;]].astype(&#39;category&#39;)
        if log_sqrt:
            df[&#34;Level_Energy&#34;] = np.sqrt(df[&#34;Level_Energy&#34;])
            df[&#34;Level_Number&#34;] = np.log10(df[&#34;Level_Number&#34;])
        if log:
            logging.info(&#34;Dropping Ground State...&#34;)
            df = df[(df[&#34;Level_Energy&#34;] != 0)]
            df[&#34;Level_Energy&#34;] = np.log10(df[&#34;Level_Energy&#34;])
            df[&#34;Level_Number&#34;] = np.log10(df[&#34;Level_Number&#34;])
        if append_ame:
            ame = load_ame(imputed_nan=True)
            df = pd.merge(df, ame, on=&#39;Target_Element_w_A&#39;)
        if basic == 0:
            basic_cols = [&#34;Level_Number&#34;, &#34;Level_Energy&#34;, &#34;Protons&#34;, &#34;Neutrons&#34;, &#34;Mass_Number&#34;, &#34;Atomic_Mass_Micro&#34;]
            df = df[basic_cols]
        elif basic == 1:
            basic_cols = [&#34;Level_Number&#34;, &#34;Level_Energy&#34;, &#34;Protons&#34;, &#34;Neutrons&#34;, &#34;Mass_Number&#34;, &#34;Atomic_Mass_Micro&#34;,
                        &#39;Mass_Excess&#39;, &#39;Binding_Energy&#39;, &#39;B_Decay_Energy&#39;, &#39;S(2n)&#39;, &#39;S(n)&#39;, &#39;S(p)&#39;]
            df = df[basic_cols] 
        if num:
            logging.info(&#34;Dropping unnecessary features and one-hot encoding categorical columns...&#34;)

            # We need to keep track of columns to normalize excluding categorical data.
            df = df.fillna(value=0)
            logging.info(&#34;Splitting dataset into training and testing...&#34;)
            x_train, x_test, y_train, y_test = train_test_split(df.drop([&#34;Level_Energy&#34;], axis=1), df[&#34;Level_Energy&#34;], test_size=frac)
            logging.info(&#34;Normalizing dataset...&#34;)
            to_scale = list(x_train.columns)
            if log_sqrt or log:
                to_scale.remove(&#34;Level_Number&#34;)
            if scaler_dir is not None:
                logging.info(&#34;Using previously saved scaler.&#34;)
                scaler = load(open(scaler_dir, &#39;rb&#39;))
            else:
                logging.info(&#34;Fitting new scaler.&#34;)
                if scaling_type == &#34;pt&#34;:
                    scaler = preprocessing.PowerTransformer().fit(x_train[to_scale])
                elif scaling_type == &#34;std&#34;:
                    scaler = preprocessing.StandardScaler().fit(x_train[to_scale])
                elif scaling_type == &#34;minmax&#34;:
                    scaler = preprocessing.MinMaxScaler().fit(x_train[to_scale])
            x_train[to_scale] = scaler.transform(x_train[to_scale])
            x_test[to_scale] = scaler.transform(x_test[to_scale])
            logging.info(&#34;Finished. Resulting dataset has shape {}, Training and Testing dataset shapes are {} and {} respesctively.&#34;.format(df.shape, x_train.shape, x_test.shape))
            return df, x_train, x_test, y_train, y_test, to_scale, scaler
        else:
            logging.info(&#34;Finished. Resulting dataset has shape {}&#34;.format(df.shape))
            return df
    else:
        return logging.error(&#34;CSV file does not exists. Check path.&#34;)


###############################################################################
####################### EXFOR DATABASE ########################################
###############################################################################
supported_modes = [&#34;neutrons&#34;, &#34;protons&#34;, &#34;alphas&#34;, &#34;deuterons&#34;, &#34;gammas&#34;, &#34;helions&#34;, &#34;all&#34;]
supported_mt_coding = [&#34;one_hot&#34;, &#34;particle_coded&#34;]
def load_exfor(log=False, low_en=False, basic=-1, num=False, frac=0.1, mode=&#34;neutrons&#34;, scaling_type=&#34;standard&#34;, 
    scaler_dir=None, filters=False, max_en=2.0E7, mt_coding=&#34;one_hot&#34;, scale_energy=False):

    if mode not in supported_modes:
        return logging.error(&#34;Specified MODE not supported. Supporte modes include: {}&#34;.format(&#39; &#39;.join([str(v) for v in supported_modes])))
    if mt_coding not in supported_mt_coding:
        return logging.error(&#34;Specified mt_coding not supported. Supported codings include: {}&#34;.format(&#39; &#39;.join([str(v) for v in supported_mt_coding])))

    logging.info(&#34; MODE: {}&#34;.format(mode))
    logging.info(&#34; LOW ENERGY: {}&#34;.format(low_en))
    logging.info(&#34; LOG: {}&#34;.format(log))
    logging.info(&#34; BASIC: {}&#34;.format(basic))
    logging.info(&#34; SCALER: {}&#34;.format(scaling_type.upper()))

    if mode == &#34;all&#34;:
        neutrons_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;neutrons&#34; + &#39;\\EXFOR_&#39; + &#34;neutrons&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        protons_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;protons&#34; + &#39;\\EXFOR_&#39; + &#34;protons&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        alphas_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;alphas&#34; + &#39;\\EXFOR_&#39; + &#34;alphas&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        deuterons_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;deuterons&#34; + &#39;\\EXFOR_&#39; + &#34;deuterons&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        gammas_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;gammas&#34; + &#39;\\EXFOR_&#39; + &#34;gammas&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        helions_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;helions&#34; + &#39;\\EXFOR_&#39; + &#34;helions&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        all_datapaths = [neutrons_datapath, protons_datapath, alphas_datapath, deuterons_datapath, gammas_datapath, helions_datapath]
        if gen_utils.check_if_files_exist(all_datapaths):
            df = pd.read_csv(neutrons_datapath, dtype=dtype_exfor).dropna()
            protons = pd.read_csv(protons_datapath, dtype=dtype_exfor).dropna()
            alphas = pd.read_csv(alphas_datapath, dtype=dtype_exfor).dropna()
            deuterons = pd.read_csv(deuterons_datapath, dtype=dtype_exfor).dropna()
            gammas = pd.read_csv(gammas_datapath, dtype=dtype_exfor).dropna()
            helions = pd.read_csv(helions_datapath, dtype=dtype_exfor).dropna()
            df = df.append([protons, alphas, deuterons, gammas, helions])
        else:
            return logging.error(&#34;One ore more files are missing. Check directories.&#34;)
    else:
        datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + mode + &#39;\\EXFOR_&#39; + mode + &#39;_MF3_AME_no_RawNaN.csv&#39;
        if os.path.exists(datapath):
            logging.info(&#34;Reading data from {}&#34;.format(datapath))
            df = pd.read_csv(datapath, dtype=dtype_exfor).dropna()
        else:
            return logging.error(&#34;CSV file does not exists. Check given path: {}&#34;.format(datapath))
        
    if filters:
        df = df[~((df.Reaction_Notation.str.contains(&#34;WTR&#34;)) | (df.Title.str.contains(&#34;DERIV&#34;)) | (df.Energy == 0) | (df.Data == 0))]
        df = df[(df.MT != &#34;203&#34;) &amp; (df.MT != &#34;1003&#34;) &amp; (df.MT != &#34;1108&#34;) &amp; (df.MT != &#34;2103&#34;)]
    if low_en:
        df = df[df.Energy &lt; max_en]
    if log:
        if (df[df.Energy == 0].shape[0] != 0) or (df[df.Data == 0].shape[0] != 0):
            logging.error(&#34;Cannot take log. Either Energy or Data contain zeros. Ignoring log.&#34;)
        else:
            df[&#34;Energy&#34;] = np.log10(df[&#34;Energy&#34;])
            df[&#34;Data&#34;] = np.log10(df[&#34;Data&#34;])

    magic_numbers = [2, 8, 20, 28, 40, 50, 82, 126, 184]
    df[&#34;N_valence&#34;] = df.N.apply(lambda neutrons: abs(neutrons - min(magic_numbers, key=lambda x:abs(x-neutrons))))
    df[&#34;Z_valence&#34;] = df.Z.apply(lambda protons: abs(protons - min(magic_numbers, key=lambda x:abs(x-protons))))
    df[&#34;P_factor&#34;] = (df[&#34;N_valence&#34;] * df[&#34;Z_valence&#34;]) / (df[&#34;N_valence&#34;] + df[&#34;Z_valence&#34;])
    df.P_factor = df.P_factor.fillna(0)
    df[&#34;N_tag&#34;] = df.N_valence.apply(lambda neutrons: &#34;even&#34; if neutrons % 2 == 0 else &#34;odd&#34;)
    df[&#34;Z_tag&#34;] = df.Z_valence.apply(lambda protons: &#34;even&#34; if protons % 2 == 0 else &#34;odd&#34;)
    df[&#34;NZ_tag&#34;] = df[&#34;N_tag&#34;] + &#34;_&#34; + df[&#34;Z_tag&#34;]

    if basic == 0:
        basic_cols = [&#34;Energy&#34;, &#34;dEnergy&#34;, &#34;Data&#34;, &#34;dData&#34;, &#34;MT&#34;, &#34;Z&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;N&#34;, &#34;A&#34;, &#34;Element_Flag&#34;]
        df = df[basic_cols]
    elif basic == 1:
        basic_cols = [&#34;Energy&#34;, &#34;dEnergy&#34;, &#34;Data&#34;, &#34;dData&#34;, &#34;MT&#34;, &#34;Z&#34;, &#34;Center_of_Mass_Flag&#34;,
                    &#34;N&#34;, &#34;A&#34;, &#34;Element_Flag&#34;, &#39;Nucleus_Radius&#39;, &#39;Neutron_Nucleus_Radius_Ratio&#39;, 
                    &#39;Mass_Excess&#39;, &#39;Binding_Energy&#39;, &#39;B_Decay_Energy&#39;, &#39;Atomic_Mass_Micro&#39;, &#39;S(2n)&#39;, 
                    &#39;S(n)&#39;, &#39;S(p)&#39;, &#39;S(2p)&#39;, &#34;N_valence&#34;, &#34;Z_valence&#34;, &#34;P_factor&#34;, &#34;N_tag&#34;, &#34;Z_tag&#34;, 
                    &#34;NZ_tag&#34;]
        df = df[basic_cols]  
    elif basic == 2:
        basic_cols = df.columns
        basic_cols = [x for x in basic_cols if not x.startswith(&#34;d&#34;)]
        df = df[basic_cols]  
    elif basic == 3:
        basic_cols = [&#34;Energy&#34;, &#34;dEnergy&#34;, &#34;Data&#34;, &#34;dData&#34;, &#34;MT&#34;, &#34;Z&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;N&#34;, &#34;A&#34;, &#34;Element_Flag&#34;, 
                    &#39;Nucleus_Radius&#39;, &#39;Neutron_Nucleus_Radius_Ratio&#39;, &#39;Mass_Excess&#39;, &#39;Binding_Energy&#39;, &#39;B_Decay_Energy&#39;, 
                    &#39;Atomic_Mass_Micro&#39;, &#39;S(n)&#39;, &#39;S(p)&#39;]
        df = df[basic_cols]

    logging.info(&#34;Data read into dataframe with shape: {}&#34;.format(df.shape))
    if num:
        logging.info(&#34;Dropping unnecessary features and one-hot encoding categorical columns...&#34;)
        if basic == 0:
            columns_drop = [&#34;dData&#34;, &#34;dEnergy&#34;]
            cat_cols = [&#34;MT&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;Element_Flag&#34;]
        elif basic == 1:
            columns_drop = [&#34;dData&#34;, &#34;dEnergy&#34;]
            cat_cols = [&#34;MT&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;Element_Flag&#34;, &#34;N_tag&#34;, &#34;Z_tag&#34;, &#34;NZ_tag&#34;]
        elif basic == 2:
            columns_drop = [&#34;Projectile&#34;, &#34;EXFOR_Status&#34;, &#34;Short_Reference&#34;, &#39;EXFOR_Accession_Number&#39;, &#39;EXFOR_SubAccession_Number&#39;, 
                            &#39;EXFOR_Pointer&#39;, &#34;Reaction_Notation&#34;, &#34;Title&#34;, &#34;Year&#34;, &#34;Author&#34;, &#34;Institute&#34;, &#34;Date&#34;, &#34;Reference&#34;,
                            &#39;Dataset_Number&#39;, &#39;EXFOR_Entry&#39;, &#39;Reference_Code&#39;, &#39;Isotope&#39;, &#39;Element&#39;,
                            &#39;Projectile_Z&#39;, &#39;Projectile_A&#39;, &#39;Projectile_N&#39;, &#34;ELV/HL&#34;, &#34;Target_Metastable_State&#34;, 
                            &#34;Product_Metastable_State&#34;, &#34;I78&#34;, &#34;O&#34;]
            cat_cols = [&#34;MT&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;Element_Flag&#34;, &#34;N_tag&#34;, &#34;Z_tag&#34;, &#34;NZ_tag&#34;]
        elif basic == 3:
            columns_drop = [&#34;dData&#34;, &#34;dEnergy&#34;]
            cat_cols = [&#34;MT&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;Element_Flag&#34;]
        else:
            columns_drop = [&#34;Projectile&#34;, &#34;EXFOR_Status&#34;, &#34;Short_Reference&#34;, &#39;EXFOR_Accession_Number&#39;, &#39;EXFOR_SubAccession_Number&#39;, 
                            &#39;EXFOR_Pointer&#39;, &#34;Reaction_Notation&#34;, &#34;Title&#34;, &#34;Year&#34;, &#34;Author&#34;, &#34;Institute&#34;, &#34;Date&#34;, &#34;Reference&#34;,
                            &#39;Dataset_Number&#39;, &#39;EXFOR_Entry&#39;, &#39;Reference_Code&#39;, &#39;Isotope&#39;, &#39;Element&#39;, &#34;dData&#34;, &#34;dEnergy&#34;,
                            &#39;Projectile_Z&#39;, &#39;Projectile_A&#39;, &#39;Projectile_N&#39;]
            cat_cols = [&#34;Target_Metastable_State&#34;, &#34;MT&#34;, &#34;Product_Metastable_State&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;I78&#34;, &#34;Element_Flag&#34;, &#34;O&#34;, &#34;N_tag&#34;, &#34;Z_tag&#34;, &#34;NZ_tag&#34;]
        
            
        df.drop(columns=columns_drop, inplace=True)
        
        if mt_coding == &#34;particle_coded&#34;:
            cat_cols.remove(&#34;MT&#34;)
            mt_codes_df = pd.read_csv(&#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\mt_codes.csv&#39;).drop(columns=[&#34;MT_Tag&#34;, &#34;MT_Reaction_Notation&#34;])
            mt_codes_df[&#34;MT&#34;] = mt_codes_df[&#34;MT&#34;].astype(str)
            # We need to keep track of columns to normalize excluding categorical data.
            norm_columns = len(df.columns) - len(cat_cols) - 2
            df = pd.concat([df, pd.get_dummies(df[cat_cols])], axis=1).drop(columns=cat_cols)
            df = pd.merge(df, mt_codes_df, on=&#39;MT&#39;).drop(columns=[&#34;MT&#34;])
        elif mt_coding == &#34;one_hot&#34;:
            # We need to keep track of columns to normalize excluding categorical data.
            norm_columns = len(df.columns) - len(cat_cols) - 1
            df = pd.concat([df, pd.get_dummies(df[cat_cols])], axis=1).drop(columns=cat_cols)


        logging.info(&#34;Splitting dataset into training and testing...&#34;)
        x_train, x_test, y_train, y_test = train_test_split(df.drop([&#34;Data&#34;], axis=1), df[&#34;Data&#34;], test_size=frac)
        
        logging.info(&#34;Normalizing dataset...&#34;)
        to_scale = list(x_train.columns)[:norm_columns]
        if not scale_energy:
            to_scale.remove(&#34;Energy&#34;)
        scaler = nuc_proc.normalize_features(x_train, to_scale, scaling_type, scaler_dir)
        x_train[to_scale] = scaler.transform(x_train[to_scale])
        x_test[to_scale] = scaler.transform(x_test[to_scale])
        return df, x_train, x_test, y_train, y_test, to_scale, scaler
    else:
        logging.info(&#34;Finished. Resulting dataset has shape {}&#34;.format(df.shape))
        return df




# IMPLEMENT ADDITION OF STABLE STATES
# columns_ensdf = [&#34;Element_w_A&#34;, &#34;N1&#34;, &#34;Elv[MeV]&#34;, &#34;spin&#34;, &#34;parity&#34;, &#34;state_half_life&#34;, &#34;Ng&#34;, &#34;J&#34;, &#34;unc&#34;, &#34;spins&#34;, &#34;nd&#34;, 
#                  &#34;m&#34;, &#34;percent&#34;, &#34;mode&#34;, &#34;other&#34;, &#34;other1&#34;, &#34;other2&#34;, &#34;other3&#34;, &#34;other4&#34;]
# ensdf_final = pd.read_csv(resulting_files_dir + &#34;ensdf_stable_state_formatted.csv&#34;, names=columns_ensdf, sep=&#34;;&#34;)
# ensdf_final[&#34;spin&#34;] = ensdf_final[&#34;spin&#34;].replace(to_replace=-1.0, value=3.5) 
# ensdf_final[&#34;parity&#34;] = ensdf_final[&#34;parity&#34;].replace(to_replace=0, value=1.0)
# ensdf_final[&#34;Element_w_A&#34;] = ensdf_final[&#34;Element_w_A&#34;].apply(lambda x: x.strip())
# ensdf_final = ensdf_final[[&#34;Element_w_A&#34;, &#34;spin&#34;, &#34;parity&#34;]]
# df2 = pd.merge(df, ensdf_final, on=&#39;Element_w_A&#39;)

# ADD RIPLE LEVEL PARAMETERES LOADING
# cut_off_cols = [&#34;Z&#34;, &#34;A&#34;, &#34;Element&#34;, &#34;Temperature_MeV&#34;, &#34;Temperature_U&#34;, &#34;Black_Shift&#34;, 
#                 &#34;Black_Shift_U&#34;, &#34;N_Lev_ENSDF&#34;, &#34;N_Max_Lev_Complete&#34;, &#34;Min_Lev_Complete&#34;, 
#                 &#34;Num_Lev_Unique_Spin&#34;, &#34;E_Max_N_Max&#34;, &#34;E_Num_Lev_U_Spin&#34;, &#34;Other&#34;, &#34;Other2&#34;, 
#                 &#34;Flag&#34;, &#34;Nox&#34;, &#34;Other3&#34;, &#34;Other4&#34;, &#34;Spin_Cutoff&#34;]
# cut_off = pd.read_csv(&#34;./ENSDF/Resulting_Files/cut_off_ensdf_energies.csv&#34;, names=cut_off_cols, sep=&#34;;&#34;)

# cut_off.tail()

# df.dtypes.apply(lambda x: x.name).to_dict()


# # ADD CAPABILITY TO ADD ENSDF AND AME SEPARATEDLEY
# supported_modes = [&#34;neutrons&#34;, &#34;protons&#34;, &#34;alphas&#34;, &#34;deuterons&#34;, &#34;gammas&#34;, &#34;helions&#34;, &#34;all&#34;]
# def load_exfor(log=False, low_en=True, basic=-1, num=False, frac=0.1, mode=&#34;neutrons&#34;, scaling_type=&#34;pt&#34;, scaler_dir=None, filters=True):
#     &#34;&#34;&#34;[summary]

#     Args:
#         log (bool, optional): [description]. Defaults to False.
#         low_en (bool, optional): [description]. Defaults to True.
#         basic (int, optional): [description]. Defaults to -1.
#         num (bool, optional): [description]. Defaults to False.
#         frac (float, optional): [description]. Defaults to 0.1.
#         mode (str, optional): [description]. Defaults to &#34;neutrons&#34;.
#         scaling_type (str, optional): [description]. Defaults to &#34;pt&#34;.
#         scaler_dir ([type], optional): [description]. Defaults to None.

#     Returns:
#         [type]: [description]
#     &#34;&#34;&#34;
    
#     ######## SETTING UP VARIABLES FOR DATA EXTRACTION ##########
#     if mode not in supported_modes:
#         return logging.error(&#34;Specified MODE not supported. Supporte modes include: {}&#34;.format(&#39; &#39;.join([str(v) for v in supported_modes])))

#     logging.info(&#34; MODE: {}&#34;.format(mode))
#     logging.info(&#34; LOW ENERGY: {}&#34;.format(low_en))
#     logging.info(&#34; LOG: {}&#34;.format(log))
#     logging.info(&#34; BASIC: {}&#34;.format(basic))
#     logging.info(&#34; SCALER: {}&#34;.format(scaling_type.upper()))

#     datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + mode + &#39;\\EXFOR_&#39; + mode + &#39;_MF3_AME_no_RawNaN.csv&#39;
#     if os.path.exists(datapath):
#         logging.info(&#34;Reading data from {}&#34;.format(datapath))
#         df = pd.read_csv(datapath, dtype=dtype_exfor).dropna()

#         if filters:
#             df = df[~((df.Reaction_Notation.str.contains(&#34;WTR&#34;)) | (df.Title.str.contains(&#34;DERIV&#34;)) | (df.Energy == 0) | (df.Data == 0))]

#         if low_en:
#             df = df[df.Energy &lt; 2.0E7]

#         if log:
#             if (df[df.Energy == 0].shape[0] != 0) or (df[df.Data == 0].shape[0] != 0):
#                 logging.error(&#34;Cannot take log. Either Energy or Data contain zeros. Ignoring log.&#34;)
#             else:
#                 df[&#34;Energy&#34;] = np.log10(df[&#34;Energy&#34;])
#                 df[&#34;Data&#34;] = np.log10(df[&#34;Data&#34;])

#         if basic == 0:
#             basic_cols = [&#34;Energy&#34;, &#34;dEnergy&#34;, &#34;Data&#34;, &#34;dData&#34;, &#34;MT&#34;, &#34;Z&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;N&#34;, &#34;A&#34;, &#34;Element_Flag&#34;]
#             df = df[basic_cols]
#         elif basic == 1:
#             # &#39;S(2p)&#39; THIS IS AN ISSUE WITH YEO TRANSFORMER FOR SOME REASON
#             basic_cols = [&#34;Energy&#34;, &#34;dEnergy&#34;, &#34;Data&#34;, &#34;dData&#34;, &#34;MT&#34;, &#34;Z&#34;, &#34;Center_of_Mass_Flag&#34;,
#                         &#34;N&#34;, &#34;A&#34;, &#34;Element_Flag&#34;, &#39;Nucleus_Radius&#39;, &#39;Neutron_Nucleus_Radius_Ratio&#39;, 
#                         &#39;Mass_Excess&#39;, &#39;Binding_Energy&#39;, &#39;B_Decay_Energy&#39;, &#39;Atomic_Mass_Micro&#39;, &#39;S(2n)&#39;, 
#                         &#39;S(n)&#39;, &#39;S(p)&#39;]
#             df = df[basic_cols]  

#         logging.info(&#34;Data read into dataframe with shape: {}&#34;.format(df.shape))
#         if num:
#             logging.info(&#34;Dropping unnecessary features and one-hot encoding categorical columns...&#34;)
#             if basic == 0 or basic == 1:
#                 columns_drop = [&#34;dData&#34;, &#34;dEnergy&#34;]
#                 cat_cols = [&#34;MT&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;Element_Flag&#34;]
#             else:
#                 columns_drop = [&#34;Projectile&#34;, &#34;EXFOR_Status&#34;, &#34;Short_Reference&#34;, &#39;EXFOR_Accession_Number&#39;, &#39;EXFOR_SubAccession_Number&#39;, 
#                                 &#39;EXFOR_Pointer&#39;, &#34;Reaction_Notation&#34;, &#34;Title&#34;, &#34;Year&#34;, &#34;Author&#34;, &#34;Institute&#34;, &#34;Date&#34;, &#34;Reference&#34;,
#                                 &#39;Dataset_Number&#39;, &#39;EXFOR_Entry&#39;, &#39;Reference_Code&#39;, &#39;Isotope&#39;, &#39;Element&#39;, &#34;dData&#34;, &#34;dEnergy&#34;,
#                                 &#39;Projectile_Z&#39;, &#39;Projectile_A&#39;, &#39;Projectile_N&#39;]
#                 cat_cols = [&#34;Target_Metastable_State&#34;, &#34;MT&#34;, &#34;Product_Metastable_State&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;I78&#34;, &#34;Element_Flag&#34;, &#34;O&#34;]

#             df.drop(columns=columns_drop, inplace=True)
#             # We need to keep track of columns to normalize excluding categorical data.
#             norm_columns = len(df.columns) - len(cat_cols) - 1
#             df = pd.concat([df, pd.get_dummies(df[cat_cols])], axis=1).drop(columns=cat_cols)
#             logging.info(&#34;Splitting dataset into training and testing...&#34;)
#             x_train, x_test, y_train, y_test = train_test_split(df.drop([&#34;Data&#34;], axis=1), df[&#34;Data&#34;], test_size=frac)
#             logging.info(&#34;Normalizing dataset...&#34;)
#             to_scale = list(x_train.columns)[:norm_columns]
#             to_scale.remove(&#34;Energy&#34;)

#             scaler = nuc_proc.normalize_features(x_train, to_scale, scaling_type, scaler_dir)

#             if scaler_dir is not None:
#                 logging.info(&#34;Using previously saved scaler.&#34;)
#                 scaler = load(open(scaler_dir, &#39;rb&#39;))
#             else:
#                 logging.info(&#34;Fitting new scaler.&#34;)
#                 if scaling_type == &#34;pt&#34;:
#                     scaler = preprocessing.PowerTransformer().fit(x_train[to_scale])
#                 elif scaling_type == &#34;std&#34;:
#                     scaler = preprocessing.StandardScaler().fit(x_train[to_scale])
#                 elif scaling_type == &#34;minmax&#34;:
#                     scaler = preprocessing.MinMaxScaler().fit(x_train[to_scale])

#             x_train[to_scale] = scaler.transform(x_train[to_scale])
#             x_test[to_scale] = scaler.transform(x_test[to_scale])
#             return df, x_train, x_test, y_train, y_test, to_scale, scaler
#         else:
#             logging.info(&#34;Finished. Resulting dataset has shape {}&#34;.format(df.shape))
#             return df
#     else:
#         return logging.error(&#34;CSV file does not exists. Check given path: {}&#34;.format(datapath))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="nucml.datasets.load_ame"><code class="name flex">
<span>def <span class="ident">load_ame</span></span>(<span>natural=False, imputed_nan=False, file='merged')</span>
</code></dt>
<dd>
<div class="desc"><p>Loads the Atomic Mass Evaluation 2016 data generated by NucML using the parsing utilities.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>natural</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, the AME data will be loaded along with rows representing natural data. Only
applicable when file='merged'.</dd>
<dt><strong><code>nan</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, the original AME data will be loaded. If False, then the linearly imputed data
is loaded. Only applicable when file='merged'</dd>
<dt><strong><code>file</code></strong> :&ensp;<code>str</code></dt>
<dd>Dataset to extract. Options include 'merged', 'mass16', 'rct1', and 'rct2'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ame (DataFrame): a pandas dataframe cantaining the queried AME data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_ame(natural=False, imputed_nan=False, file=&#34;merged&#34;):    
    &#34;&#34;&#34;Loads the Atomic Mass Evaluation 2016 data generated by NucML using the parsing utilities.

    Args:
        natural (bool): if True, the AME data will be loaded along with rows representing natural data. Only
            applicable when file=&#39;merged&#39;.
        nan (bool): If True, the original AME data will be loaded. If False, then the linearly imputed data 
            is loaded. Only applicable when file=&#39;merged&#39;
        file (str): Dataset to extract. Options include &#39;merged&#39;, &#39;mass16&#39;, &#39;rct1&#39;, and &#39;rct2&#39;.
    Returns:
        ame (DataFrame): a pandas dataframe cantaining the queried AME data.

    &#34;&#34;&#34;
    directory = ame_dir_path
    if file.lower() == &#34;merged&#34;:
        if natural:
            if imputed_nan:
                ame_file_path = os.path.join(directory, &#34;AME_Natural_Properties_no_NaN.csv&#34;)
            else:
                ame_file_path = os.path.join(directory, &#34;AME_Natural_Properties_w_NaN.csv&#34;)
        else:
            if imputed_nan:
                ame_file_path = os.path.join(directory, &#34;AME_all_merged_no_NaN.csv&#34;)
            else:
                ame_file_path = os.path.join(directory, &#34;AME_all_merged.csv&#34;)

        logging.info(&#34;AME: Reading and loading Atomic Mass Evaluation files from: \n {}&#34;.format(ame_file_path))
        ame = pd.read_csv(ame_file_path)
        ame[[&#34;N&#34;, &#34;Z&#34;, &#34;A&#34;]] = ame[[&#34;N&#34;, &#34;Z&#34;, &#34;A&#34;]].astype(int)
    elif file.lower() in [&#34;mass16&#34;, &#34;rct1&#34;, &#34;rct2&#34;]:
        ame_file_path = os.path.join(ame_dir_path, &#34;AME_{}.csv&#34;.format(file))
        logging.info(&#34;AME: Reading and loading the Atomic Mass Evaluation file from: \n {}&#34;.format(ame_file_path))
        ame = pd.read_csv(ame_file_path)
    return ame</code></pre>
</details>
</dd>
<dt id="nucml.datasets.load_ensdf"><code class="name flex">
<span>def <span class="ident">load_ensdf</span></span>(<span>cutoff=False, append_ame=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads the Evalauted Nuclear Structure Data File generated using NucML.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cutoff</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, the RIPL cutoff ENSDF file is loaded. Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>DataFrame</code></dt>
<dd>if num=True, the function returns 6 variables.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_ensdf(cutoff=False, append_ame=False):
    &#34;&#34;&#34;Loads the Evalauted Nuclear Structure Data File generated using NucML.

    Args:
        cutoff (bool, optional): If True, the RIPL cutoff ENSDF file is loaded. Defaults to False.

    Returns:
        DataFrame: if num=True, the function returns 6 variables. 
    &#34;&#34;&#34;    
    if cutoff:
        datapath = os.path.join(ensdf_path, &#34;CSV_Files/ensdf_cutoff.csv&#34;)
    else:
        datapath = os.path.join(ensdf_path, &#34;CSV_Files/ensdf.csv&#34;)

    logging.info(&#34;Reading data from {}&#34;.format(datapath))
    df = pd.read_csv(datapath)
    df[&#34;Level_Number&#34;] = df[&#34;Level_Number&#34;].astype(int)
    if append_ame:
        ame = load_ame(imputed_nan=True)
        df = pd.merge(df, ame, on=&#39;Element_w_A&#39;)
    return df</code></pre>
</details>
</dd>
<dt id="nucml.datasets.load_ensdf_ground_states"><code class="name flex">
<span>def <span class="ident">load_ensdf_ground_states</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads the ENSDF file. Only ground state information.</p>
<h2 id="returns">Returns</h2>
<p>DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_ensdf_ground_states():
    &#34;&#34;&#34;Loads the ENSDF file. Only ground state information.

    Returns:
        DataFrame
    &#34;&#34;&#34;    
    df = pd.read_csv(os.path.join(ensdf_path, &#34;CSV_Files/ensdf_stable_state_formatted.csv&#34;), header=None, sep=&#39;|&#39;)
    df = df.drop(columns=[1, 2, 6])
    df.columns = [&#34;Element_w_A&#34;, &#34;Spin&#34;, &#34;Parity&#34;, &#34;Half_Life&#34;, &#34;Flag&#34;, &#34;ENSDF_Spin&#34;, &#34;Num_Decay_Modes&#34;, &#34;Modifier&#34;, &#34;Decay_Info&#34;]
    for col in df.columns:
        df[col] = df[col].astype(str).str.strip()
    df.Num_Decay_Modes = df.Num_Decay_Modes.replace(&#34;0+#&#34;, -1)
    for col in df.columns:
        if col not in [&#34;Element_w_A&#34;, &#34;Flag&#34;, &#34;ENSDF_Spin&#34;, &#34;Modifier&#34;, &#34;Decay_Info&#34;]:
            df[col] = pd.to_numeric(df[col])
    return df</code></pre>
</details>
</dd>
<dt id="nucml.datasets.load_ensdf_headers"><code class="name flex">
<span>def <span class="ident">load_ensdf_headers</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads ENSDF headers from RIPL .dat files.</p>
<p>The features include "Element_w_A", "A", "Z", "Number_of_Levels", "Number_of_Gammas", "N_max", "N_c", "Sn", "Sp"</p>
<h2 id="returns">Returns</h2>
<p>DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_ensdf_headers():
    &#34;&#34;&#34;Loads ENSDF headers from RIPL .dat files.

    The features include &#34;Element_w_A&#34;, &#34;A&#34;, &#34;Z&#34;, &#34;Number_of_Levels&#34;, &#34;Number_of_Gammas&#34;, &#34;N_max&#34;, &#34;N_c&#34;, &#34;Sn&#34;, &#34;Sp&#34;

    Returns:
        DataFrame
    &#34;&#34;&#34;    
    csv_file = os.path.join(ensdf_path, &#34;CSV_Files/all_ensdf_headers_formatted.csv&#34;)
    ensdf_index_col = [&#34;Element_w_A&#34;, &#34;A&#34;, &#34;Z&#34;, &#34;Number_of_Levels&#34;, &#34;Number_of_Gammas&#34;, &#34;N_max&#34;, &#34;N_c&#34;, &#34;Sn&#34;, &#34;Sp&#34;]
    ensdf_index = pd.read_csv(csv_file, names=ensdf_index_col, sep=&#34;|&#34;)
    return ensdf_index</code></pre>
</details>
</dd>
<dt id="nucml.datasets.load_ensdf_isotopic"><code class="name flex">
<span>def <span class="ident">load_ensdf_isotopic</span></span>(<span>ELAAA, filetype='levels')</span>
</code></dt>
<dd>
<div class="desc"><p>Loads level or gamma records for a given isotope.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ELAAA</code></strong> :&ensp;<code>str</code></dt>
<dd>isotope to query (i.e. u235, cl35, 239Pu)</dd>
<dt><strong><code>filetype</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>specifies if level or gamma records are to be extracted. Options
include "levels" and "gammas". Defaults to "levels".</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_ensdf_isotopic(ELAAA, filetype=&#34;levels&#34;):
    &#34;&#34;&#34;Loads level or gamma records for a given isotope.

    Args:
        ELAAA (str): isotope to query (i.e. u235, cl35, 239Pu)
        filetype (str, optional): specifies if level or gamma records are to be extracted. Options 
            include &#34;levels&#34; and &#34;gammas&#34;. Defaults to &#34;levels&#34;.

    Returns:
        DataFrame
    &#34;&#34;&#34;    
    ELAAA = gen_utils.parse_elaaa(ELAAA, parse_for=&#34;ENSDF&#34;)
    file = os.path.join(ensdf_path, &#34;Elemental_ENSDF/Elemental_ENSDF_no_Header_F/{}.txt&#34;.format(ELAAA))
    elemental = pd.read_csv(file, header=None, sep=&#34;|&#34;)
    elemental[0] = pd.to_numeric(elemental[0].astype(str).str.strip())

    if filetype.lower() == &#34;levels&#34;:
        elemental_level_records = elemental[elemental[0].notna()]
        elemental_level_records = elemental_level_records.reset_index(drop=True).drop(columns=[7,8])
        elemental_level_records.columns = [&#34;Level_Number&#34;, &#34;Energy&#34;, &#34;Spin&#34;, &#34;Parity&#34;, &#34;Half_Life&#34;, &#34;Gammas&#34;, &#34;Flag&#34;, &#34;ENSDF_Spin&#34;, &#34;Num_Decay_Modes&#34;, &#34;Decay_Info&#34;]
        elemental_level_records.Num_Decay_Modes = elemental_level_records.Num_Decay_Modes.replace(&#34;0+#&#34;, -1)

        for col in elemental_level_records.columns:
            elemental_level_records[col] = elemental_level_records[col].astype(str).str.strip()

        for col in elemental_level_records.columns:
            if col not in [&#34;Flag&#34;, &#34;ENSDF_Spin&#34;, &#34;Decay_Info&#34;]:
                elemental_level_records[col] = pd.to_numeric(elemental_level_records[col])

        return elemental_level_records
    elif filetype.lower() == &#34;gammas&#34;:
        elemental[0] = elemental[0].fillna(method=&#39;ffill&#39;)
        elemental[1] = pd.to_numeric(elemental[1].str.strip())
        elemental_gamma_records = elemental[~elemental[1].notna()]
        new_columns = elemental_gamma_records[11].str.split(expand=True)
        elemental_gamma_records = elemental_gamma_records.drop(columns=[1, 2, 3, 4, 5, 6, 10, 11])
        elemental_gamma_records = pd.concat([elemental_gamma_records, new_columns], axis=1)
        elemental_gamma_records.columns = [&#34;Level_Record&#34;, &#34;Final_State&#34;, &#34;Energy&#34;, &#34;Gamma_Decay_Prob&#34;, &#34;Electromag_Decay_Prob&#34;, &#34;ICC&#34;]
        for col in elemental_gamma_records.columns:
            elemental_gamma_records[col] = pd.to_numeric(elemental_gamma_records[col])
        return elemental_gamma_records</code></pre>
</details>
</dd>
<dt id="nucml.datasets.load_ensdf_ml"><code class="name flex">
<span>def <span class="ident">load_ensdf_ml</span></span>(<span>log_sqrt=False, log=False, append_ame=False, basic=-1, num=False, frac=0.3, scaling_type='std', scaler_dir=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_ensdf_ml(log_sqrt=False, log=False, append_ame=False, basic=-1, num=False, frac=0.3, scaling_type=&#34;std&#34;, scaler_dir=None):
    path = &#39;../../ENSDF/CSV_Files/Level_Density&#39; # use your path
    all_files = glob.glob(path + &#34;/*.csv&#34;)

    if len(all_files) != 0:

        li = []

        for filename in all_files:
            df = pd.read_csv(filename, index_col=None, header=0)
            li.append(df)

        df = pd.concat(li, axis=0, ignore_index=True)

        df[&#34;Level_Number&#34;] = df[&#34;Level_Number&#34;].astype(int)
        df[[&#34;Target_Element_w_A&#34;]] = df[[&#34;Target_Element_w_A&#34;]].astype(&#39;category&#39;)
        if log_sqrt:
            df[&#34;Level_Energy&#34;] = np.sqrt(df[&#34;Level_Energy&#34;])
            df[&#34;Level_Number&#34;] = np.log10(df[&#34;Level_Number&#34;])
        if log:
            logging.info(&#34;Dropping Ground State...&#34;)
            df = df[(df[&#34;Level_Energy&#34;] != 0)]
            df[&#34;Level_Energy&#34;] = np.log10(df[&#34;Level_Energy&#34;])
            df[&#34;Level_Number&#34;] = np.log10(df[&#34;Level_Number&#34;])
        if append_ame:
            ame = load_ame(imputed_nan=True)
            df = pd.merge(df, ame, on=&#39;Target_Element_w_A&#39;)
        if basic == 0:
            basic_cols = [&#34;Level_Number&#34;, &#34;Level_Energy&#34;, &#34;Protons&#34;, &#34;Neutrons&#34;, &#34;Mass_Number&#34;, &#34;Atomic_Mass_Micro&#34;]
            df = df[basic_cols]
        elif basic == 1:
            basic_cols = [&#34;Level_Number&#34;, &#34;Level_Energy&#34;, &#34;Protons&#34;, &#34;Neutrons&#34;, &#34;Mass_Number&#34;, &#34;Atomic_Mass_Micro&#34;,
                        &#39;Mass_Excess&#39;, &#39;Binding_Energy&#39;, &#39;B_Decay_Energy&#39;, &#39;S(2n)&#39;, &#39;S(n)&#39;, &#39;S(p)&#39;]
            df = df[basic_cols] 
        if num:
            logging.info(&#34;Dropping unnecessary features and one-hot encoding categorical columns...&#34;)

            # We need to keep track of columns to normalize excluding categorical data.
            df = df.fillna(value=0)
            logging.info(&#34;Splitting dataset into training and testing...&#34;)
            x_train, x_test, y_train, y_test = train_test_split(df.drop([&#34;Level_Energy&#34;], axis=1), df[&#34;Level_Energy&#34;], test_size=frac)
            logging.info(&#34;Normalizing dataset...&#34;)
            to_scale = list(x_train.columns)
            if log_sqrt or log:
                to_scale.remove(&#34;Level_Number&#34;)
            if scaler_dir is not None:
                logging.info(&#34;Using previously saved scaler.&#34;)
                scaler = load(open(scaler_dir, &#39;rb&#39;))
            else:
                logging.info(&#34;Fitting new scaler.&#34;)
                if scaling_type == &#34;pt&#34;:
                    scaler = preprocessing.PowerTransformer().fit(x_train[to_scale])
                elif scaling_type == &#34;std&#34;:
                    scaler = preprocessing.StandardScaler().fit(x_train[to_scale])
                elif scaling_type == &#34;minmax&#34;:
                    scaler = preprocessing.MinMaxScaler().fit(x_train[to_scale])
            x_train[to_scale] = scaler.transform(x_train[to_scale])
            x_test[to_scale] = scaler.transform(x_test[to_scale])
            logging.info(&#34;Finished. Resulting dataset has shape {}, Training and Testing dataset shapes are {} and {} respesctively.&#34;.format(df.shape, x_train.shape, x_test.shape))
            return df, x_train, x_test, y_train, y_test, to_scale, scaler
        else:
            logging.info(&#34;Finished. Resulting dataset has shape {}&#34;.format(df.shape))
            return df
    else:
        return logging.error(&#34;CSV file does not exists. Check path.&#34;)</code></pre>
</details>
</dd>
<dt id="nucml.datasets.load_evaluation"><code class="name flex">
<span>def <span class="ident">load_evaluation</span></span>(<span>ELAAA, MT, mode='neutrons', library='endfb8.0', mev_to_ev=True, mb_to_b=True, log=True, drop_u=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads an evaluation file for a specific element and reaction channel. It is important
to inspect the returned data since it queries an external database which extracted data from ENDF
using a particular script. It has been found that some particular reactions are not included.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ELAAA</code></strong> :&ensp;<code>str</code></dt>
<dd>element to query. The string must start with the element followed by the mass number (i.e. U233, Cl35) </dd>
<dt><strong><code>MT</code></strong> :&ensp;<code>int</code></dt>
<dd>reaction channel to query. Must be an integer (i.e. 1, 2, 3)</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>str</code></dt>
<dd>projectile of the reaction of interest. Only "neutrons" and "protons" is allowed for now.</dd>
<dt><strong><code>library</code></strong> :&ensp;<code>str</code></dt>
<dd>evaluation library to query. Allowed options include endfb8.0, jendl4.0, jeff3.3, and tendl.2019.</dd>
<dt><strong><code>mev_to_ev</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, it converts the energy from MeV to eV.</dd>
<dt><strong><code>mb_to_b</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, it converts the cross sections from millibarns to barns.</dd>
<dt><strong><code>log</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, it applies the log10 to both the Energy and the Cross Section.</dd>
<dt><strong><code>drop_u</code></strong> :&ensp;<code>bool</code></dt>
<dd>sometimes, evaluation files contain uncertainty values. If True, these features are removed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>evaluation (DataFrame): pandas DataFrame containing the ENDF datapoints.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_evaluation(ELAAA, MT, mode=&#34;neutrons&#34;, library=&#34;endfb8.0&#34;, mev_to_ev=True, mb_to_b=True, log=True, drop_u=True):
    &#34;&#34;&#34;Reads an evaluation file for a specific element and reaction channel. It is important
    to inspect the returned data since it queries an external database which extracted data from ENDF 
    using a particular script. It has been found that some particular reactions are not included.

    Args:
        ELAAA (str): element to query. The string must start with the element followed by the mass number (i.e. U233, Cl35) 
        MT (int): reaction channel to query. Must be an integer (i.e. 1, 2, 3)
        mode (str): projectile of the reaction of interest. Only &#34;neutrons&#34; and &#34;protons&#34; is allowed for now.
        library (str): evaluation library to query. Allowed options include endfb8.0, jendl4.0, jeff3.3, and tendl.2019.
        mev_to_ev (bool): if True, it converts the energy from MeV to eV.
        mb_to_b (bool): if True, it converts the cross sections from millibarns to barns.
        log (bool): if True, it applies the log10 to both the Energy and the Cross Section.
        drop_u (bool): sometimes, evaluation files contain uncertainty values. If True, these features are removed.
    Returns:
        evaluation (DataFrame): pandas DataFrame containing the ENDF datapoints.
    &#34;&#34;&#34;
    MT = gen_utils.parse_mt(MT)
    ELAAA = gen_utils.parse_elaaa(ELAAA, parse_for=&#39;endf&#39;)

    if mode == &#34;protons&#34;:
        projectile = &#39;p&#39;
    elif mode == &#34;neutrons&#34;:
        projectile = &#39;n&#39;

    path = os.path.join(evaluations_path, &#39;{}/{}/{}/tables/xs/{}-{}-{}.{}&#39;.format(mode, ELAAA, library, projectile, ELAAA, MT, library))    

    file = Path(path)
    if file.is_file():
        logging.info(&#34;EVALUATION: Extracting data from {}&#34;.format(path))
        evaluation = pd.read_csv(path, skiprows=5, header=None, names=[&#34;Energy&#34;, &#34;Data&#34;, &#34;dDataLow&#34;, &#34;dDataUpp&#34;], delim_whitespace=True)
        if mev_to_ev:
            logging.info(&#34;EVALUATION: Converting MeV to eV...&#34;)
            evaluation[&#34;Energy&#34;] = evaluation[&#34;Energy&#34;]*1E6
        if mb_to_b:
            logging.info(&#34;EVALUATION: Converting mb to b...&#34;)
            evaluation[&#34;Data&#34;] = evaluation[&#34;Data&#34;]*0.001
        if log:
            evaluation[&#34;Energy&#34;] = np.log10(evaluation[&#34;Energy&#34;])
            evaluation[&#34;Data&#34;] = np.log10(evaluation[&#34;Data&#34;])
            evaluation[&#34;dDataLow&#34;] = np.log10(evaluation[&#34;dDataLow&#34;])
            evaluation[&#34;dDataUpp&#34;] = np.log10(evaluation[&#34;dDataUpp&#34;])
        if drop_u:
            if &#34;dData&#34; in list(evaluation.columns):
                evaluation = evaluation.drop(columns=[&#34;dDataLow&#34;])
            if &#34;dData2&#34; in list(evaluation.columns):
                evaluation = evaluation.drop(columns=[&#34;dDataUpp&#34;])
            if &#34;dDataLow&#34; in list(evaluation.columns):
                evaluation = evaluation.drop(columns=[&#34;dDataLow&#34;])
            if &#34;dDataUpp&#34; in list(evaluation.columns):
                evaluation = evaluation.drop(columns=[&#34;dDataUpp&#34;])
        logging.info(&#34;EVALUATION: Finished. ENDF data contains {} datapoints.&#34;.format(evaluation.shape[0]))
        return evaluation
    else:
        raise FileNotFoundError(&#39;Evaluation file does not exists at {}&#39;.format(path))</code></pre>
</details>
</dd>
<dt id="nucml.datasets.load_exfor"><code class="name flex">
<span>def <span class="ident">load_exfor</span></span>(<span>log=False, low_en=False, basic=-1, num=False, frac=0.1, mode='neutrons', scaling_type='standard', scaler_dir=None, filters=False, max_en=20000000.0, mt_coding='one_hot', scale_energy=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_exfor(log=False, low_en=False, basic=-1, num=False, frac=0.1, mode=&#34;neutrons&#34;, scaling_type=&#34;standard&#34;, 
    scaler_dir=None, filters=False, max_en=2.0E7, mt_coding=&#34;one_hot&#34;, scale_energy=False):

    if mode not in supported_modes:
        return logging.error(&#34;Specified MODE not supported. Supporte modes include: {}&#34;.format(&#39; &#39;.join([str(v) for v in supported_modes])))
    if mt_coding not in supported_mt_coding:
        return logging.error(&#34;Specified mt_coding not supported. Supported codings include: {}&#34;.format(&#39; &#39;.join([str(v) for v in supported_mt_coding])))

    logging.info(&#34; MODE: {}&#34;.format(mode))
    logging.info(&#34; LOW ENERGY: {}&#34;.format(low_en))
    logging.info(&#34; LOG: {}&#34;.format(log))
    logging.info(&#34; BASIC: {}&#34;.format(basic))
    logging.info(&#34; SCALER: {}&#34;.format(scaling_type.upper()))

    if mode == &#34;all&#34;:
        neutrons_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;neutrons&#34; + &#39;\\EXFOR_&#39; + &#34;neutrons&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        protons_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;protons&#34; + &#39;\\EXFOR_&#39; + &#34;protons&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        alphas_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;alphas&#34; + &#39;\\EXFOR_&#39; + &#34;alphas&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        deuterons_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;deuterons&#34; + &#39;\\EXFOR_&#39; + &#34;deuterons&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        gammas_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;gammas&#34; + &#39;\\EXFOR_&#39; + &#34;gammas&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        helions_datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + &#34;helions&#34; + &#39;\\EXFOR_&#39; + &#34;helions&#34; + &#39;_MF3_AME_no_RawNaN.csv&#39;
        all_datapaths = [neutrons_datapath, protons_datapath, alphas_datapath, deuterons_datapath, gammas_datapath, helions_datapath]
        if gen_utils.check_if_files_exist(all_datapaths):
            df = pd.read_csv(neutrons_datapath, dtype=dtype_exfor).dropna()
            protons = pd.read_csv(protons_datapath, dtype=dtype_exfor).dropna()
            alphas = pd.read_csv(alphas_datapath, dtype=dtype_exfor).dropna()
            deuterons = pd.read_csv(deuterons_datapath, dtype=dtype_exfor).dropna()
            gammas = pd.read_csv(gammas_datapath, dtype=dtype_exfor).dropna()
            helions = pd.read_csv(helions_datapath, dtype=dtype_exfor).dropna()
            df = df.append([protons, alphas, deuterons, gammas, helions])
        else:
            return logging.error(&#34;One ore more files are missing. Check directories.&#34;)
    else:
        datapath = &#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\EXFOR_&#39; + mode + &#39;\\EXFOR_&#39; + mode + &#39;_MF3_AME_no_RawNaN.csv&#39;
        if os.path.exists(datapath):
            logging.info(&#34;Reading data from {}&#34;.format(datapath))
            df = pd.read_csv(datapath, dtype=dtype_exfor).dropna()
        else:
            return logging.error(&#34;CSV file does not exists. Check given path: {}&#34;.format(datapath))
        
    if filters:
        df = df[~((df.Reaction_Notation.str.contains(&#34;WTR&#34;)) | (df.Title.str.contains(&#34;DERIV&#34;)) | (df.Energy == 0) | (df.Data == 0))]
        df = df[(df.MT != &#34;203&#34;) &amp; (df.MT != &#34;1003&#34;) &amp; (df.MT != &#34;1108&#34;) &amp; (df.MT != &#34;2103&#34;)]
    if low_en:
        df = df[df.Energy &lt; max_en]
    if log:
        if (df[df.Energy == 0].shape[0] != 0) or (df[df.Data == 0].shape[0] != 0):
            logging.error(&#34;Cannot take log. Either Energy or Data contain zeros. Ignoring log.&#34;)
        else:
            df[&#34;Energy&#34;] = np.log10(df[&#34;Energy&#34;])
            df[&#34;Data&#34;] = np.log10(df[&#34;Data&#34;])

    magic_numbers = [2, 8, 20, 28, 40, 50, 82, 126, 184]
    df[&#34;N_valence&#34;] = df.N.apply(lambda neutrons: abs(neutrons - min(magic_numbers, key=lambda x:abs(x-neutrons))))
    df[&#34;Z_valence&#34;] = df.Z.apply(lambda protons: abs(protons - min(magic_numbers, key=lambda x:abs(x-protons))))
    df[&#34;P_factor&#34;] = (df[&#34;N_valence&#34;] * df[&#34;Z_valence&#34;]) / (df[&#34;N_valence&#34;] + df[&#34;Z_valence&#34;])
    df.P_factor = df.P_factor.fillna(0)
    df[&#34;N_tag&#34;] = df.N_valence.apply(lambda neutrons: &#34;even&#34; if neutrons % 2 == 0 else &#34;odd&#34;)
    df[&#34;Z_tag&#34;] = df.Z_valence.apply(lambda protons: &#34;even&#34; if protons % 2 == 0 else &#34;odd&#34;)
    df[&#34;NZ_tag&#34;] = df[&#34;N_tag&#34;] + &#34;_&#34; + df[&#34;Z_tag&#34;]

    if basic == 0:
        basic_cols = [&#34;Energy&#34;, &#34;dEnergy&#34;, &#34;Data&#34;, &#34;dData&#34;, &#34;MT&#34;, &#34;Z&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;N&#34;, &#34;A&#34;, &#34;Element_Flag&#34;]
        df = df[basic_cols]
    elif basic == 1:
        basic_cols = [&#34;Energy&#34;, &#34;dEnergy&#34;, &#34;Data&#34;, &#34;dData&#34;, &#34;MT&#34;, &#34;Z&#34;, &#34;Center_of_Mass_Flag&#34;,
                    &#34;N&#34;, &#34;A&#34;, &#34;Element_Flag&#34;, &#39;Nucleus_Radius&#39;, &#39;Neutron_Nucleus_Radius_Ratio&#39;, 
                    &#39;Mass_Excess&#39;, &#39;Binding_Energy&#39;, &#39;B_Decay_Energy&#39;, &#39;Atomic_Mass_Micro&#39;, &#39;S(2n)&#39;, 
                    &#39;S(n)&#39;, &#39;S(p)&#39;, &#39;S(2p)&#39;, &#34;N_valence&#34;, &#34;Z_valence&#34;, &#34;P_factor&#34;, &#34;N_tag&#34;, &#34;Z_tag&#34;, 
                    &#34;NZ_tag&#34;]
        df = df[basic_cols]  
    elif basic == 2:
        basic_cols = df.columns
        basic_cols = [x for x in basic_cols if not x.startswith(&#34;d&#34;)]
        df = df[basic_cols]  
    elif basic == 3:
        basic_cols = [&#34;Energy&#34;, &#34;dEnergy&#34;, &#34;Data&#34;, &#34;dData&#34;, &#34;MT&#34;, &#34;Z&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;N&#34;, &#34;A&#34;, &#34;Element_Flag&#34;, 
                    &#39;Nucleus_Radius&#39;, &#39;Neutron_Nucleus_Radius_Ratio&#39;, &#39;Mass_Excess&#39;, &#39;Binding_Energy&#39;, &#39;B_Decay_Energy&#39;, 
                    &#39;Atomic_Mass_Micro&#39;, &#39;S(n)&#39;, &#39;S(p)&#39;]
        df = df[basic_cols]

    logging.info(&#34;Data read into dataframe with shape: {}&#34;.format(df.shape))
    if num:
        logging.info(&#34;Dropping unnecessary features and one-hot encoding categorical columns...&#34;)
        if basic == 0:
            columns_drop = [&#34;dData&#34;, &#34;dEnergy&#34;]
            cat_cols = [&#34;MT&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;Element_Flag&#34;]
        elif basic == 1:
            columns_drop = [&#34;dData&#34;, &#34;dEnergy&#34;]
            cat_cols = [&#34;MT&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;Element_Flag&#34;, &#34;N_tag&#34;, &#34;Z_tag&#34;, &#34;NZ_tag&#34;]
        elif basic == 2:
            columns_drop = [&#34;Projectile&#34;, &#34;EXFOR_Status&#34;, &#34;Short_Reference&#34;, &#39;EXFOR_Accession_Number&#39;, &#39;EXFOR_SubAccession_Number&#39;, 
                            &#39;EXFOR_Pointer&#39;, &#34;Reaction_Notation&#34;, &#34;Title&#34;, &#34;Year&#34;, &#34;Author&#34;, &#34;Institute&#34;, &#34;Date&#34;, &#34;Reference&#34;,
                            &#39;Dataset_Number&#39;, &#39;EXFOR_Entry&#39;, &#39;Reference_Code&#39;, &#39;Isotope&#39;, &#39;Element&#39;,
                            &#39;Projectile_Z&#39;, &#39;Projectile_A&#39;, &#39;Projectile_N&#39;, &#34;ELV/HL&#34;, &#34;Target_Metastable_State&#34;, 
                            &#34;Product_Metastable_State&#34;, &#34;I78&#34;, &#34;O&#34;]
            cat_cols = [&#34;MT&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;Element_Flag&#34;, &#34;N_tag&#34;, &#34;Z_tag&#34;, &#34;NZ_tag&#34;]
        elif basic == 3:
            columns_drop = [&#34;dData&#34;, &#34;dEnergy&#34;]
            cat_cols = [&#34;MT&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;Element_Flag&#34;]
        else:
            columns_drop = [&#34;Projectile&#34;, &#34;EXFOR_Status&#34;, &#34;Short_Reference&#34;, &#39;EXFOR_Accession_Number&#39;, &#39;EXFOR_SubAccession_Number&#39;, 
                            &#39;EXFOR_Pointer&#39;, &#34;Reaction_Notation&#34;, &#34;Title&#34;, &#34;Year&#34;, &#34;Author&#34;, &#34;Institute&#34;, &#34;Date&#34;, &#34;Reference&#34;,
                            &#39;Dataset_Number&#39;, &#39;EXFOR_Entry&#39;, &#39;Reference_Code&#39;, &#39;Isotope&#39;, &#39;Element&#39;, &#34;dData&#34;, &#34;dEnergy&#34;,
                            &#39;Projectile_Z&#39;, &#39;Projectile_A&#39;, &#39;Projectile_N&#39;]
            cat_cols = [&#34;Target_Metastable_State&#34;, &#34;MT&#34;, &#34;Product_Metastable_State&#34;, &#34;Center_of_Mass_Flag&#34;, &#34;I78&#34;, &#34;Element_Flag&#34;, &#34;O&#34;, &#34;N_tag&#34;, &#34;Z_tag&#34;, &#34;NZ_tag&#34;]
        
            
        df.drop(columns=columns_drop, inplace=True)
        
        if mt_coding == &#34;particle_coded&#34;:
            cat_cols.remove(&#34;MT&#34;)
            mt_codes_df = pd.read_csv(&#39;C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\EXFOR\\CSV_Files\\mt_codes.csv&#39;).drop(columns=[&#34;MT_Tag&#34;, &#34;MT_Reaction_Notation&#34;])
            mt_codes_df[&#34;MT&#34;] = mt_codes_df[&#34;MT&#34;].astype(str)
            # We need to keep track of columns to normalize excluding categorical data.
            norm_columns = len(df.columns) - len(cat_cols) - 2
            df = pd.concat([df, pd.get_dummies(df[cat_cols])], axis=1).drop(columns=cat_cols)
            df = pd.merge(df, mt_codes_df, on=&#39;MT&#39;).drop(columns=[&#34;MT&#34;])
        elif mt_coding == &#34;one_hot&#34;:
            # We need to keep track of columns to normalize excluding categorical data.
            norm_columns = len(df.columns) - len(cat_cols) - 1
            df = pd.concat([df, pd.get_dummies(df[cat_cols])], axis=1).drop(columns=cat_cols)


        logging.info(&#34;Splitting dataset into training and testing...&#34;)
        x_train, x_test, y_train, y_test = train_test_split(df.drop([&#34;Data&#34;], axis=1), df[&#34;Data&#34;], test_size=frac)
        
        logging.info(&#34;Normalizing dataset...&#34;)
        to_scale = list(x_train.columns)[:norm_columns]
        if not scale_energy:
            to_scale.remove(&#34;Energy&#34;)
        scaler = nuc_proc.normalize_features(x_train, to_scale, scaling_type, scaler_dir)
        x_train[to_scale] = scaler.transform(x_train[to_scale])
        x_test[to_scale] = scaler.transform(x_test[to_scale])
        return df, x_train, x_test, y_train, y_test, to_scale, scaler
    else:
        logging.info(&#34;Finished. Resulting dataset has shape {}&#34;.format(df.shape))
        return df</code></pre>
</details>
</dd>
<dt id="nucml.datasets.load_ripl_parameters"><code class="name flex">
<span>def <span class="ident">load_ripl_parameters</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads the RIPL level cut-off parameters file.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>DataFrame</code></dt>
<dd>pandas DataFrame</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_ripl_parameters():
    &#34;&#34;&#34;Loads the RIPL level cut-off parameters file.

    Returns:
        DataFrame: pandas DataFrame 
    &#34;&#34;&#34;    
    ripl_params = pd.read_csv(os.path.join(ensdf_path, &#34;CSV_Files/ripl_cut_off_energies.csv&#34;))
    return ripl_params</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="nucml" href="index.html">nucml</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="nucml.datasets.load_ame" href="#nucml.datasets.load_ame">load_ame</a></code></li>
<li><code><a title="nucml.datasets.load_ensdf" href="#nucml.datasets.load_ensdf">load_ensdf</a></code></li>
<li><code><a title="nucml.datasets.load_ensdf_ground_states" href="#nucml.datasets.load_ensdf_ground_states">load_ensdf_ground_states</a></code></li>
<li><code><a title="nucml.datasets.load_ensdf_headers" href="#nucml.datasets.load_ensdf_headers">load_ensdf_headers</a></code></li>
<li><code><a title="nucml.datasets.load_ensdf_isotopic" href="#nucml.datasets.load_ensdf_isotopic">load_ensdf_isotopic</a></code></li>
<li><code><a title="nucml.datasets.load_ensdf_ml" href="#nucml.datasets.load_ensdf_ml">load_ensdf_ml</a></code></li>
<li><code><a title="nucml.datasets.load_evaluation" href="#nucml.datasets.load_evaluation">load_evaluation</a></code></li>
<li><code><a title="nucml.datasets.load_exfor" href="#nucml.datasets.load_exfor">load_exfor</a></code></li>
<li><code><a title="nucml.datasets.load_ripl_parameters" href="#nucml.datasets.load_ripl_parameters">load_ripl_parameters</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>