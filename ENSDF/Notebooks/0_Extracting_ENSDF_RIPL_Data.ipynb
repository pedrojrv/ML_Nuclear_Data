{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSDF and RIPL Parsing\n",
    "\n",
    "This notebook demonstrates the use of the ENSDF utilities to parse and generate the ENSDF csv files. It also demonstrates the use of the RIPL level parameteres file to cut-off the ENSDF csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T01:15:17.932981Z",
     "start_time": "2020-08-14T01:15:17.929481Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.paath.append(\"../..\")\n",
    "\n",
    "import nucml.datasets as nuc_data\n",
    "import nucml.ensdf.parsing_utilities as ensdf_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T19:55:49.609102Z",
     "start_time": "2020-08-15T19:55:49.597099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nucml.ensdf.parsing_utilities' from '../..\\\\nucml\\\\ensdf\\\\parsing_utilities.py'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(nuc_data)\n",
    "importlib.reload(ensdf_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing ENSDF/RIPL Data\n",
    "\n",
    "The ENSDF data is being extracted from the RIPL formated zXXX.dat files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T19:55:50.990233Z",
     "start_time": "2020-08-15T19:55:50.987732Z"
    }
   },
   "outputs": [],
   "source": [
    "# the `nuc_data` module contains all unique exfor elements\n",
    "elements = nuc_data.exfor_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_ripl_names()` function allows to get the path to all `.dat` files in the levels directory. We will use these to create our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T19:56:41.411540Z",
     "start_time": "2020-08-15T19:56:41.404538Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RIPL: Searching ../RIPL_3/levels/levels/ directory for .dat files...\n",
      "INFO:root:RIPL: Finished. Found 118 .dat files.\n"
     ]
    }
   ],
   "source": [
    "ripl_levels_dir = \"../RIPL_3/levels/levels/\"\n",
    "names = ensdf_utils.get_ripl_names(ripl_levels_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the header for each file which contains information we will be useful like the number of levels per isotope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T01:25:11.235940Z",
     "start_time": "2020-08-14T01:23:05.296130Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:HEADER: Extracting ENSDF headers ...\n",
      "INFO:root:HEADER: Finished. Saved to ../tmp/all_ensdf_headers_formatted.csv\n"
     ]
    }
   ],
   "source": [
    "tmp_directory = \"../CSV_Files/\"\n",
    "ensdf_utils.get_header(names, tmp_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now specify the directory we're the element-wise ensdf files will be stored. Whatever directory is specified, the `generate_elemental_ensdf()` function will create three directories where different types of files will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T02:51:35.933630Z",
     "start_time": "2020-08-14T02:43:55.122163Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:GEN UTILS: Directory already exists. Re-initializing...\n",
      "INFO:root:GEN UTILS: Directory restarted.\n",
      "INFO:root:ENSDF Elemental: Extracting ENSDF data per element with header...\n",
      "INFO:root:GEN UTILS: Directory already exists. Re-initializing...\n",
      "INFO:root:GEN UTILS: Directory restarted.\n",
      "INFO:root:ENSDF Elemental: Removing header from ENSDF elemental files...\n",
      "INFO:root:GEN UTILS: Directory already exists. Re-initializing...\n",
      "INFO:root:GEN UTILS: Directory restarted.\n",
      "INFO:root:ENSDF Elemental: Formatting files...\n",
      "INFO:root:ENSDF Elemental: Finished formating data.\n"
     ]
    }
   ],
   "source": [
    "elemental_dir = \"../Elemental_ENSDF/\"\n",
    "ensdf_utils.generate_elemental_ensdf(names, tmp_directory, elemental_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elemental files contain all known nuclear levels, if for some reason you only need a ground state CSV file. This can be created using the `get_stable_states()` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T04:03:43.954328Z",
     "start_time": "2020-08-14T03:59:13.504978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STABLE STATES: Extracting stable states from .dat files...\n",
      "STABLE STATES: Formatting text file...\n",
      "STABLE STATES: Finished.\n"
     ]
    }
   ],
   "source": [
    "ensdf_utils.get_stable_states(names, tmp_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the elemental files created, we can know get a single ENSDF file containing all nuclear levels for all isotopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T08:04:50.113432Z",
     "start_time": "2020-08-14T08:04:42.091407Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creatign DataFrame with Basic ENSDF data ...\n",
      "INFO:root:Finished creating list of dataframes.\n"
     ]
    }
   ],
   "source": [
    "ensdf_utils.generate_ensdf_csv(tmp_directory, elemental_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutting ENSDF using RIPL CutOff Parameters\n",
    "\n",
    "We can easily remove nuclear levels above the given parameteres using the the RIPL level-params.dat file. If you wish to create your own cut-off parameters be sure to modify the level-params.dat following the original formatting, otherwise this script will not work.\n",
    "\n",
    "First we start by parsing the levels-params.data file from RIPL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripl_level_params_dir = \"../RIPL_3/levels/\"\n",
    "ensdf_utils.get_level_parameters(ripl_level_params_dir, saving_directory=tmp_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the created cut-off csv file to remove nuclear levels from the previuosly created ensdf.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T18:44:53.138108Z",
     "start_time": "2020-08-15T18:44:44.275928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ENSDF CutOff: Loading ENSDF and RIPL parameters...\n",
      "INFO:root:ENSDF CutOff: Cutting off ENSDF...\n",
      "INFO:root:ENSDF CutOff: Finished.\n"
     ]
    }
   ],
   "source": [
    "elemental_hf_dir = \"../Elemental_ENSDF/Elemental_ENSDF_no_Header_F/\"\n",
    "ensdf_utils.generate_cutoff_ensdf(tmp_directory, elemental_hf_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREVIOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T04:06:41.007527Z",
     "start_time": "2020-08-13T04:06:41.005026Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Search all files withing the ENSDF directory\n",
    "# directory = \"../ENSDF_Files/\"\n",
    "\n",
    "# print(\"Searching directory for RIPL ENSDF files...\")\n",
    "# names = []\n",
    "# for root, dirs, files in os.walk(directory):\n",
    "#     for file in files:\n",
    "#         if file.endswith(\".dat\"):\n",
    "#             names.append(os.path.join(root, file))\n",
    "            \n",
    "# print(\"Gathered {} RIPL ENSDF files.\".format(len(names)))\n",
    "# names = natsorted(names)\n",
    "\n",
    "# # We use the list of documents to extract only the data we need\n",
    "# print(\"Extracting ENSDF headers ...\")\n",
    "# for i in names:\n",
    "#     with open(i) as infile, open(resulting_files_dir + 'all_ensdf_headers.txt', 'a') as outfile:\n",
    "#         for line in infile:\n",
    "#             for z in elements:\n",
    "#                 if z in line.split():\n",
    "#                     outfile.write(line)\n",
    "# print(\"Finished extracting headers.\")\n",
    "\n",
    "# # Using the document with all data we insert commas following the EXFOR format\n",
    "# print(\"Formatting ENSDF header data...\")\n",
    "# with open(resulting_files_dir + \"all_ensdf_headers.txt\") as infile, open(resulting_files_dir + 'all_ensdf_headers_formatted.csv', 'w') as outfile:\n",
    "#     for line in infile:\n",
    "#         if line.strip():\n",
    "#             string = list(line)\n",
    "#             for i, j in enumerate([5, 10, 15, 20, 25, 30, 35, 47]):\n",
    "#                 string.insert(i + j, ';')\n",
    "#             outfile.write(\"\".join(string))\n",
    "# print(\"Finished formating data.\")\n",
    "\n",
    "# ensdf_index_col = [\"SYMB\", \"A\", \"Z\", \"Nol\", \"Nog\", \"Nmax\", \"Nc\", \"Sn\", \"Sp\"]\n",
    "# ensdf_index = pd.read_csv(os.path.join(saving_directory, \"all_ensdf_headers_formatted.csv\"), names=ensdf_index_col, sep=\";\")\n",
    "# ensdf_index[\"Text_Filenames\"] = ensdf_index[\"SYMB\"].apply(lambda x: x.strip())\n",
    "\n",
    "# Verify that all EXFOR isotopes have information avaliable in ENSDF database.\n",
    "\n",
    "# len(elements) == len(ensdf_index.SYMB.unique())\n",
    "\n",
    "# element_list_endf = ensdf_index.SYMB.tolist() # string that files start with\n",
    "# element_list_names = ensdf_index.Text_Filenames.tolist() # same strings but stripped\n",
    "\n",
    "# ensdf_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting ENSDF Data per Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ENSDF data per element with header ...\n",
      "Finished extracting data per element with header.\n"
     ]
    }
   ],
   "source": [
    "# print(\"Extracting ENSDF data per element with header ...\")\n",
    "# for e in element_list_endf:\n",
    "#     for i in names:\n",
    "#         with open(i, \"r\") as infile, open((\"Elemental_ENSDF/\" + str(e).strip() + '.txt'), 'a') as outfile:\n",
    "#             lines = infile.readlines()\n",
    "#             for z, line in enumerate(lines):\n",
    "#                 if line.startswith(str(e)):\n",
    "#                     for y in range(0, 1 + ensdf_index[ensdf_index[\"SYMB\"] == e][[\"Nol\"]].values[0][0] + ensdf_index[ensdf_index[\"SYMB\"] == e][[\"Nog\"]].values[0][0]):\n",
    "#                         outfile.write(lines[z + y])\n",
    "# print(\"Finished extracting data per element with header.\")\n",
    "\n",
    "# \"./Elementa_ENSDF/\".strip(\"/\") + \"_v1/\"\n",
    "\n",
    "# os.path.join(\"./Elementa_ENSDF/\", \"\").strip(\"/\") + \"_v1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Stable States Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting stable states ...\n",
      "Finished extracting REACTION NOTATION.\n"
     ]
    }
   ],
   "source": [
    "# print(\"Extracting stable states ...\")\n",
    "# for e in element_list_endf:\n",
    "#     for i in names:\n",
    "#         with open(i, \"r\") as infile, open((resulting_files_dir + \"ensdf_stable_state.txt\"), 'a') as outfile:\n",
    "#             lines = infile.readlines()\n",
    "#             for z, line in enumerate(lines):\n",
    "#                 if line.startswith(str(e)):\n",
    "#                     outfile.write(e + lines[1 + z])\n",
    "# print(\"Finished extracting stable states.\")\n",
    "\n",
    "# print(\"Formatting ENSDF stable states file ...\")\n",
    "# with open(resulting_files_dir + \"ensdf_stable_state.txt\") as infile, open(resulting_files_dir + 'ensdf_stable_state_formatted.csv', 'w') as outfile:\n",
    "#     for line in infile:\n",
    "#         if line.strip():\n",
    "#             string = list(line)\n",
    "#             for i, j in enumerate([5, 10, 19, 25, 28, 39, 42, 44, 46, 59, 68, 71, 74, 85, 93, 96, 107, 115]):\n",
    "#                 string.insert(i + j, ';')\n",
    "#             outfile.write(\"\".join(string))\n",
    "# print(\"Finished formating data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting ENSDF Data per Element without Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ENSDF data per element without header ...\n",
      "Finished extracting data per element without header.\n"
     ]
    }
   ],
   "source": [
    "# print(\"Extracting ENSDF data per element without header ...\")\n",
    "# for e in element_list_endf:\n",
    "#     for i in names:\n",
    "#         with open(i, \"r\") as infile, open((\"Elemental_ENSDF_v2/\" + str(e).strip() + '.txt'), 'a') as outfile:\n",
    "#             lines = infile.readlines()\n",
    "#             for z, line in enumerate(lines):\n",
    "#                 if line.startswith(str(e)):\n",
    "#                     for y in range(1, 1 + ensdf_index[ensdf_index[\"SYMB\"] == e][[\"Nol\"]].values[0][0] + ensdf_index[ensdf_index[\"SYMB\"] == e][[\"Nog\"]].values[0][0]):\n",
    "#                         outfile.write(lines[z + y])\n",
    "# print(\"Finished extracting data per element without header.\")\n",
    "\n",
    "# print(\"Formatting ENSDF data...\")\n",
    "# for i in element_list_names:\n",
    "#     with open(\"Elemental_ENSDF_v2/\" + i + \".txt\") as infile, open(\"Elemental_ENSDF_v3/\" + i + \".txt\", 'w') as outfile:\n",
    "#         for line in infile:\n",
    "#             if line.strip():\n",
    "#                 string = list(line)\n",
    "#                 for i, j in enumerate([4, 15, 20, 23, 34, 37, 39, 43, 54, 65, 66]):\n",
    "#                     string.insert(i + j, ';')\n",
    "#                 outfile.write(\"\".join(string))\n",
    "# print(\"Finished formating data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making DataFrame for ENSDF Inferal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creatign DataFrame with Basic ENSDF data ...\n",
      "Finished creating list of dataframes.\n"
     ]
    }
   ],
   "source": [
    "# print(\"Creatign DataFrame with Basic ENSDF data ...\")\n",
    "# appended_data = []\n",
    "# ensdf_cols = [\"Level_Number\", \"Level_Energy\", \"Spin\", \"Parity\", \"Half_Life\", \n",
    "#               \"Number_Gammas\", \"Flag_Spin\", \"Flag_Energy\", \"Other\", \"Other2\", \"Other3\", \"Other4\"]\n",
    "\n",
    "# for e in element_list_names:\n",
    "#     with open(\"./ENSDF/Elemental_ENSDF_v3/\" + e + \".txt\", \"r\") as infile:\n",
    "#         element_ensdf = pd.read_csv(infile, sep=\";\", names=ensdf_cols)\n",
    "#         element_ensdf[\"Level_Number\"] = element_ensdf[\"Level_Number\"].astype(str)\n",
    "#         element_ensdf[\"Level_Number\"] = element_ensdf[\"Level_Number\"].apply(lambda x: x.strip())\n",
    "#         element_ensdf[\"Level_Number\"] = element_ensdf[\"Level_Number\"].replace(to_replace=\"\", value=np.nan)\n",
    "#         element_ensdf = element_ensdf.dropna().reset_index(drop=True)\n",
    "#         element_ensdf[\"Element_w_A\"] = e\n",
    "#         appended_data.append(element_ensdf)\n",
    "# print(\"Finished creating list of dataframes.\")\n",
    "\n",
    "# appended_data = pd.concat(appended_data)\n",
    "\n",
    "# appended_data = appended_data[[\"Level_Number\", \"Level_Energy\", \"Spin\", \"Parity\", \"Element_w_A\"]]\n",
    "\n",
    "# appended_data.head()\n",
    "\n",
    "# len(appended_data[\"Element_w_A\"].value_counts())\n",
    "\n",
    "# appended_data_2 = pd.merge(appended_data, df[[\"Target_Protons\", \"Target_Neutrons\", \"Atomic_Mass_Micro\", \"Target_Mass_Number\", \"Element\", \"Element_w_A\"]].drop_duplicates(subset=['Target_Protons', 'Target_Neutrons']), on='Element_w_A')\n",
    "\n",
    "# appended_data.shape[0] == appended_data_2.shape[0]\n",
    "\n",
    "# appended_data_2.to_csv(\"./ENSDF/ensdf_v1.csv\", index=False)\n",
    "\n",
    "# appended_data_2 = pd.read_csv(\"./ENSDF/ensdf_v1.csv\")\n",
    "\n",
    "# This dataset is for ENSDF prediction.\n",
    "\n",
    "# appended_data_2.head()\n",
    "\n",
    "# appended_data_2[appended_data_2.Target_Protons == 92]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Stable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_ensdf = [\"Element_w_A\", \"N1\", \"Elv[MeV]\", \"spin\", \"parity\", \"state_half_life\", \"Ng\", \"J\", \"unc\", \"spins\", \"nd\", \n",
    "#                  \"m\", \"percent\", \"mode\", \"other\", \"other1\", \"other2\", \"other3\", \"other4\"]\n",
    "# ensdf_final = pd.read_csv(resulting_files_dir + \"ensdf_stable_state_formatted.csv\", names=columns_ensdf, sep=\";\")\n",
    "# ensdf_final[\"spin\"] = ensdf_final[\"spin\"].replace(to_replace=-1.0, value=3.5) \n",
    "# ensdf_final[\"parity\"] = ensdf_final[\"parity\"].replace(to_replace=0, value=1.0)\n",
    "# ensdf_final[\"Element_w_A\"] = ensdf_final[\"Element_w_A\"].apply(lambda x: x.strip())\n",
    "# ensdf_final = ensdf_final[[\"Element_w_A\", \"spin\", \"parity\"]]\n",
    "\n",
    "# df2 = pd.merge(df, ensdf_final, on='Element_w_A')\n",
    "\n",
    "# df2.to_csv(\"../ML_Data/working_xs_v2_unsk.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutoff Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the document with all data we insert commas following the EXFOR format\n",
    "# print(\"Formatting ENSDF cutoff data...\")\n",
    "# with open(resulting_files_dir + \"levels-param.data.txt\") as infile, open(resulting_files_dir + 'cut_off_ensdf_energies.csv', 'w') as outfile:\n",
    "#     for line in infile:\n",
    "#         if line.strip():\n",
    "#             string = list(line)\n",
    "#             for i, j in enumerate([4, 8, 11, 21, 31, 41, 51, 55, 59, 63, 67, 76, 85, 96, 98, 100, 104, 116]):\n",
    "#                 string.insert(i + j, ';')\n",
    "#             outfile.write(\"\".join(string))\n",
    "# print(\"Finished formating cutoff data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Z</th>\n",
       "      <th>A</th>\n",
       "      <th>Element</th>\n",
       "      <th>Temperature_MeV</th>\n",
       "      <th>Temperature_U</th>\n",
       "      <th>Black_Shift</th>\n",
       "      <th>Black_Shift_U</th>\n",
       "      <th>N_Lev_ENSDF</th>\n",
       "      <th>N_Max_Lev_Complete</th>\n",
       "      <th>Min_Lev_Complete</th>\n",
       "      <th>Num_Lev_Unique_Spin</th>\n",
       "      <th>E_Max_N_Max</th>\n",
       "      <th>E_Num_Lev_U_Spin</th>\n",
       "      <th>Other</th>\n",
       "      <th>Other2</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Nox</th>\n",
       "      <th>Other3</th>\n",
       "      <th>Other4</th>\n",
       "      <th>Spin_Cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>117</td>\n",
       "      <td>293</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>118</td>\n",
       "      <td>293</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>117</td>\n",
       "      <td>294</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3351</th>\n",
       "      <td>118</td>\n",
       "      <td>294</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>118</td>\n",
       "      <td>295</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Z    A Element  Temperature_MeV  Temperature_U  Black_Shift  \\\n",
       "3348  117  293      17              0.0            0.0          0.0   \n",
       "3349  118  293      18              0.0            0.0          0.0   \n",
       "3350  117  294      17              0.0            0.0          0.0   \n",
       "3351  118  294      18              0.0            0.0          0.0   \n",
       "3352  118  295      18              0.0            0.0          0.0   \n",
       "\n",
       "      Black_Shift_U  N_Lev_ENSDF  N_Max_Lev_Complete  Min_Lev_Complete  \\\n",
       "3348            0.0            1                   1                 1   \n",
       "3349            0.0            1                   1                 1   \n",
       "3350            0.0            1                   1                 1   \n",
       "3351            0.0            1                   1                 1   \n",
       "3352            0.0            1                   1                 1   \n",
       "\n",
       "      Num_Lev_Unique_Spin  E_Max_N_Max  E_Num_Lev_U_Spin        Other Other2  \\\n",
       "3348                    1          0.0               0.0                       \n",
       "3349                    1          0.0               0.0                       \n",
       "3350                    1          0.0               0.0                       \n",
       "3351                    1          0.0               0.0                       \n",
       "3352                    1          0.0               0.0                       \n",
       "\n",
       "     Flag  Nox        Other3  Other4  Spin_Cutoff  \n",
       "3348         0                   0.0          NaN  \n",
       "3349         0                   0.0          NaN  \n",
       "3350         0                   0.0          NaN  \n",
       "3351         0                   0.0          NaN  \n",
       "3352         0                   0.0          NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut_off_cols = [\"Z\", \"A\", \"Element\", \"Temperature_MeV\", \"Temperature_U\", \"Black_Shift\", \n",
    "#                 \"Black_Shift_U\", \"N_Lev_ENSDF\", \"N_Max_Lev_Complete\", \"Min_Lev_Complete\", \n",
    "#                 \"Num_Lev_Unique_Spin\", \"E_Max_N_Max\", \"E_Num_Lev_U_Spin\", \"Other\", \"Other2\", \n",
    "#                 \"Flag\", \"Nox\", \"Other3\", \"Other4\", \"Spin_Cutoff\"]\n",
    "# cut_off = pd.read_csv(\"./ENSDF/Resulting_Files/cut_off_ensdf_energies.csv\", names=cut_off_cols, sep=\";\")\n",
    "\n",
    "# cut_off.tail()\n",
    "\n",
    "# cut_off = cut_off[[\"Z\", \"A\", \"Element\", \"N_Lev_ENSDF\", \"N_Max_Lev_Complete\", \"E_Max_N_Max\"]]\n",
    "# cut_off[\"Element\"] = cut_off[\"Element\"].apply(lambda x: x.strip())\n",
    "# cut_off[\"Element_w_A\"] = cut_off[\"A\"].astype(str) + cut_off[\"Element\"]\n",
    "# cut_off = cut_off[~cut_off.Element.str.contains(r'\\d')]\n",
    "\n",
    "# print(\"Reading data into dataframe...\")\n",
    "# df = pd.read_csv(\"./ENSDF/ensdf_v1.csv\")\n",
    "# print(\"Data read into dataframe!\")\n",
    "\n",
    "# # Converting specific columns to datatype 'string'\n",
    "# str_cols = [\"Spin\", \"Parity\", \"Element_w_A\", \"Element\"]\n",
    "# df[str_cols] = df[str_cols].astype('category')\n",
    "\n",
    "# # Converting remaining columns to numeric type. \n",
    "# for col in list(df.columns):\n",
    "#     if col not in str_cols:\n",
    "#         df[col] = df[col].astype(float)\n",
    "\n",
    "# # Converting proton, neutron and mass number features to integers\n",
    "# int_cols = [\"Level_Number\", \"Target_Protons\", \"Target_Neutrons\", \"Target_Mass_Number\"]\n",
    "# df[int_cols] = df[int_cols].astype(int)\n",
    "\n",
    "# basic_cols = [\"Level_Number\", \"Level_Energy\", \"Target_Protons\", \"Target_Neutrons\", \"Atomic_Mass_Micro\", \"Element_w_A\"]\n",
    "# df = df[basic_cols]\n",
    "\n",
    "# element_list_names = df.Element_w_A.unique()\n",
    "\n",
    "# print(\"Creatign Cut-off Dataframe ...\")\n",
    "# appended_data = []\n",
    "# ensdf_cols = [\"Level_Number\", \"Level_Energy\", \"Spin\", \"Parity\", \"Half_Life\", \n",
    "#               \"Number_Gammas\", \"Flag_Spin\", \"Flag_Energy\", \"Other\", \"Other2\", \"Other3\", \"Other4\"]\n",
    "\n",
    "# for e in element_list_names:\n",
    "#     with open(\"./ENSDF/Elemental_ENSDF_v3/\" + e + \".txt\", \"r\") as infile:\n",
    "#         element_ensdf = pd.read_csv(infile, sep=\";\", names=ensdf_cols)\n",
    "#         element_ensdf[\"Level_Number\"] = element_ensdf[\"Level_Number\"].astype(str)\n",
    "#         element_ensdf[\"Level_Number\"] = element_ensdf[\"Level_Number\"].apply(lambda x: x.strip())\n",
    "#         element_ensdf[\"Level_Number\"] = element_ensdf[\"Level_Number\"].replace(to_replace=\"\", value=np.nan)\n",
    "#         element_ensdf = element_ensdf.dropna().reset_index(drop=True)\n",
    "#         element_ensdf[\"Element_w_A\"] = e\n",
    "#         x = cut_off[cut_off.Element_w_A == e].N_Max_Lev_Complete.values[0]\n",
    "#         if x == 0:\n",
    "#             element_ensdf = element_ensdf.iloc[0:1]\n",
    "#         else:\n",
    "#             element_ensdf = element_ensdf.iloc[0:x]\n",
    "#         appended_data.append(element_ensdf)\n",
    "# print(\"Finished creating list of dataframes.\")\n",
    "\n",
    "# appended_data = pd.concat(appended_data)\n",
    "# appended_data = appended_data[[\"Level_Number\", \"Level_Energy\", \"Spin\", \"Parity\", \"Element_w_A\"]]\n",
    "\n",
    "# appended_data_2 = pd.merge(appended_data, df[[\"Target_Protons\", \"Target_Neutrons\", \"Atomic_Mass_Micro\", \"Element_w_A\"]].drop_duplicates(subset=['Target_Protons', 'Target_Neutrons']), on='Element_w_A')\n",
    "\n",
    "# appended_data_2.to_csv(\"./ENSDF/ensdf_v2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
