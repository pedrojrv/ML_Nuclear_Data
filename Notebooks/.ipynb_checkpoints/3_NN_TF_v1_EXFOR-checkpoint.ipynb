{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Cross Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:09:49.637567Z",
     "start_time": "2020-04-09T06:09:46.034849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import importlib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "\n",
    "from  IPython import display\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:09:49.643560Z",
     "start_time": "2020-04-09T06:09:49.639558Z"
    }
   },
   "outputs": [],
   "source": [
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:09:49.753584Z",
     "start_time": "2020-04-09T06:09:49.645560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:09:49.758585Z",
     "start_time": "2020-04-09T06:09:49.755585Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:09:49.762586Z",
     "start_time": "2020-04-09T06:09:49.759586Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# This allows us to import the nucml utilities\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:25:11.890558Z",
     "start_time": "2020-04-09T06:25:11.874564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish importing scripts.\n"
     ]
    }
   ],
   "source": [
    "import nucml.exfor.data_utilities as exfor_utils\n",
    "import nucml.endf.data_utilities as endf_utils\n",
    "import nucml.plot.plotting_utilities as plot_utils\n",
    "import nucml.datasets as nuc_data\n",
    "importlib.reload(exfor_utils)\n",
    "importlib.reload(endf_utils)\n",
    "importlib.reload(plot_utils)\n",
    "importlib.reload(nuc_data)\n",
    "print(\"Finish importing scripts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data: ENSDF/RIPL Known and Cut-Off\n",
    "# Creating Training, Validation, and Testing Datasets and Data Standarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:09:49.844605Z",
     "start_time": "2020-04-09T06:09:49.841604Z"
    }
   },
   "outputs": [],
   "source": [
    "log_E = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:09:49.848606Z",
     "start_time": "2020-04-09T06:09:49.845605Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "test_size = 1 - 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:15:22.829787Z",
     "start_time": "2020-04-09T06:14:41.131005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\ML_Data\\EXFOR_neutrons\\EXFOR_neutrons_MF3_AME_no_NaNRaw.csv\n",
      "Reading data into dataframe...\n",
      "Extracting samples from dataframe.\n",
      "EXFOR extracted DataFrame has shape:  (1744, 66)\n",
      "Data read into dataframe with shape:  (1744, 10)\n",
      "Dropping unnecessary features and one-hot encoding categorical columns...\n",
      "Splitting dataset into training and testing...\n",
      "Normalizing dataset...\n",
      "Finished. Resulting dataset has shape  (1744, 49) \n",
      "Training and Testing dataset shapes are (1395, 48) and (349, 48) respesctively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "kwarg = {\"elemental\":True, \"Z\":17}\n",
    "\n",
    "df, x_train, x_test, y_train, y_test, to_scale, scaler = nuc_data.load_exfor(num=True, basic=True, frac=test_size, **kwarg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:16:36.375801Z",
     "start_time": "2020-04-09T06:16:36.370799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36    1019\n",
       "35     472\n",
       "37     253\n",
       "Name: Target_Mass_Number, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Target_Mass_Number.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:16:53.711040Z",
     "start_time": "2020-04-09T06:16:53.706049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Energy', 'Data', 'Target_Protons', 'Target_Neutrons',\n",
       "       'Target_Mass_Number', 'MT_1', 'MT_102', 'MT_16', 'MT_17', 'MT_2',\n",
       "       'MT_3', 'MT_4', 'MT_101', 'MT_103', 'MT_104', 'MT_41', 'MT_9000',\n",
       "       'MT_105', 'MT_32', 'MT_51', 'MT_33', 'MT_107', 'MT_24', 'MT_155',\n",
       "       'MT_158', 'MT_159', 'MT_108', 'MT_29', 'MT_1108', 'MT_113', 'MT_106',\n",
       "       'MT_22', 'MT_1003', 'MT_9001', 'MT_28', 'MT_111', 'MT_203', 'MT_2103',\n",
       "       'MT_112', 'MT_37', 'MT_161', 'MT_152', 'MT_153', 'MT_18', 'MT_160',\n",
       "       'Frame_L', 'Frame_C', 'Target_Flag_I', 'Target_Flag_N'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:22:40.240686Z",
     "start_time": "2020-04-09T06:22:40.221682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\ML_Data\\ENDF_neutrons\\\\Cl035\\endfb8.0\\tables\\xs\\n-Cl035-MT103.endfb8.0\n",
      "Convering MeV to eV...\n",
      "Convering mb to b...\n",
      "Finish reading ENDF data with shape:  (8791, 2)\n"
     ]
    }
   ],
   "source": [
    "# load_endf() extracts ENDF data from ML_Data directory\n",
    "endf_cl = nuc_data.load_endf(\"Cl035\", \"MT103\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:23:04.438406Z",
     "start_time": "2020-04-09T06:23:04.428412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../EXFOR/New_Data/Chlorine_Data/new_cl_np.csv\n",
      "Finish reading ENDF data with shape:  (12, 4)\n"
     ]
    }
   ],
   "source": [
    "# Loading LBNL new chlorine measurments\n",
    "new_data = endf_utils.load_new(\"../EXFOR/New_Data/Chlorine_Data/new_cl_np.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:27:12.374029Z",
     "start_time": "2020-04-09T06:27:12.325019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting samples from dataframe.\n",
      "EXFOR extracted DataFrame has shape:  (215, 49)\n",
      "Expanded Dataset has shape:  (12, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy</th>\n",
       "      <th>Data</th>\n",
       "      <th>Target_Protons</th>\n",
       "      <th>Target_Neutrons</th>\n",
       "      <th>Target_Mass_Number</th>\n",
       "      <th>MT_1</th>\n",
       "      <th>MT_102</th>\n",
       "      <th>MT_16</th>\n",
       "      <th>MT_17</th>\n",
       "      <th>MT_2</th>\n",
       "      <th>MT_3</th>\n",
       "      <th>MT_4</th>\n",
       "      <th>MT_101</th>\n",
       "      <th>MT_103</th>\n",
       "      <th>MT_104</th>\n",
       "      <th>MT_41</th>\n",
       "      <th>MT_9000</th>\n",
       "      <th>MT_105</th>\n",
       "      <th>MT_32</th>\n",
       "      <th>MT_51</th>\n",
       "      <th>MT_33</th>\n",
       "      <th>MT_107</th>\n",
       "      <th>MT_24</th>\n",
       "      <th>MT_155</th>\n",
       "      <th>MT_158</th>\n",
       "      <th>MT_159</th>\n",
       "      <th>MT_108</th>\n",
       "      <th>MT_29</th>\n",
       "      <th>MT_1108</th>\n",
       "      <th>MT_113</th>\n",
       "      <th>MT_106</th>\n",
       "      <th>MT_22</th>\n",
       "      <th>MT_1003</th>\n",
       "      <th>MT_9001</th>\n",
       "      <th>MT_28</th>\n",
       "      <th>MT_111</th>\n",
       "      <th>MT_203</th>\n",
       "      <th>MT_2103</th>\n",
       "      <th>MT_112</th>\n",
       "      <th>MT_37</th>\n",
       "      <th>MT_161</th>\n",
       "      <th>MT_152</th>\n",
       "      <th>MT_153</th>\n",
       "      <th>MT_18</th>\n",
       "      <th>MT_160</th>\n",
       "      <th>Frame_L</th>\n",
       "      <th>Frame_C</th>\n",
       "      <th>Target_Flag_I</th>\n",
       "      <th>Target_Flag_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2420000</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2420000</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2520000</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2520000</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2580000</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Energy    Data  Target_Protons  Target_Neutrons  Target_Mass_Number  MT_1  \\\n",
       "0  2420000  0.0166              17               18                  35     0   \n",
       "1  2420000  0.0196              17               18                  35     0   \n",
       "2  2520000  0.0261              17               18                  35     0   \n",
       "3  2520000  0.0257              17               18                  35     0   \n",
       "4  2580000  0.0446              17               18                  35     0   \n",
       "\n",
       "   MT_102  MT_16  MT_17  MT_2  MT_3  MT_4  MT_101  MT_103  MT_104  MT_41  \\\n",
       "0       0      0      0     0     0     0       0       1       0      0   \n",
       "1       0      0      0     0     0     0       0       1       0      0   \n",
       "2       0      0      0     0     0     0       0       1       0      0   \n",
       "3       0      0      0     0     0     0       0       1       0      0   \n",
       "4       0      0      0     0     0     0       0       1       0      0   \n",
       "\n",
       "   MT_9000  MT_105  MT_32  MT_51  MT_33  MT_107  MT_24  MT_155  MT_158  \\\n",
       "0        0       0      0      0      0       0      0       0       0   \n",
       "1        0       0      0      0      0       0      0       0       0   \n",
       "2        0       0      0      0      0       0      0       0       0   \n",
       "3        0       0      0      0      0       0      0       0       0   \n",
       "4        0       0      0      0      0       0      0       0       0   \n",
       "\n",
       "   MT_159  MT_108  MT_29  MT_1108  MT_113  MT_106  MT_22  MT_1003  MT_9001  \\\n",
       "0       0       0      0        0       0       0      0        0        0   \n",
       "1       0       0      0        0       0       0      0        0        0   \n",
       "2       0       0      0        0       0       0      0        0        0   \n",
       "3       0       0      0        0       0       0      0        0        0   \n",
       "4       0       0      0        0       0       0      0        0        0   \n",
       "\n",
       "   MT_28  MT_111  MT_203  MT_2103  MT_112  MT_37  MT_161  MT_152  MT_153  \\\n",
       "0      0       0       0        0       0      0       0       0       0   \n",
       "1      0       0       0        0       0      0       0       0       0   \n",
       "2      0       0       0        0       0      0       0       0       0   \n",
       "3      0       0       0        0       0      0       0       0       0   \n",
       "4      0       0       0        0       0      0       0       0       0   \n",
       "\n",
       "   MT_18  MT_160  Frame_L  Frame_C  Target_Flag_I  Target_Flag_N  \n",
       "0      0       0        1        0              1              0  \n",
       "1      0       0        1        0              1              0  \n",
       "2      0       0        1        0              1              0  \n",
       "3      0       0        1        0              1              0  \n",
       "4      0       0        1        0              1              0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cl_data_kwargs = {\"Z\":17, \"A\":35, \"MT\":\"MT_103\", \"append_exfor\":True, \"log_e\":False}\n",
    "new_cl_data = exfor_utils.load_exfor_newdata(\"../EXFOR/New_Data/Chlorine_Data/new_cl_np.csv\", df=df, **new_cl_data_kwargs)\n",
    "new_cl_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization - Learning Rate\n",
    "\n",
    "A gradually reducing learning rate with time performes better (jumping around). The `schedules.InverseTimeDecay` decreases rate hyperbolicallly to 1/2 of the base rate at 1000 epochs, 1/3 at 2000 and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Fit Funciton - TensorBoard Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:16:58.185766Z",
     "start_time": "2020-04-09T06:16:58.178766Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimizer(lr_schedule):\n",
    "    return tf.keras.optimizers.Adam(lr_schedule)\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tfdocs.modeling.EpochDots(),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200), # val_loss\n",
    "        tf.keras.callbacks.TensorBoard(logdir/name)]\n",
    "\n",
    "def compile_and_fit(model, name, train_dataset, test_dataset, STEPS_PER_EPOCH, BATCH_SIZE=None, \n",
    "                    optimizer=None, max_epochs=10000, DECAY_EPOCHS=1000):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "        0.001, decay_steps=STEPS_PER_EPOCH*DECAY_EPOCHS,\n",
    "        decay_rate=1, staircase=False)\n",
    "    \n",
    "    if optimizer is None:\n",
    "        optimizer = get_optimizer(lr_schedule)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse',\n",
    "                  metrics=['mae', 'mse'])\n",
    "    model.summary()\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = STEPS_PER_EPOCH,\n",
    "        epochs=max_epochs,\n",
    "        validation_data=test_dataset,\n",
    "        callbacks=get_callbacks(name),\n",
    "        verbose=0)        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:17:00.461256Z",
     "start_time": "2020-04-09T06:16:59.082546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "cpu_strategy = tf.distribute.OneDeviceStrategy(device=\"/CPU:0\")\n",
    "single_gpu_strategy =  tf.distribute.OneDeviceStrategy(device=\"/GPU:0\")\n",
    "gpu_strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "print('Number of devices: {}'.format(gpu_strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a tf.data.Dataset Generator\n",
    "\n",
    "The larger the `BATCH_SIZE`, the more efficient TensorFlow operates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:17:06.869619Z",
     "start_time": "2020-04-09T06:17:06.866756Z"
    }
   },
   "outputs": [],
   "source": [
    "N_VALIDATION = len(x_test)\n",
    "N_TRAIN = len(x_train)\n",
    "BUFFER_SIZE = N_TRAIN\n",
    "BATCH_SIZE = 500\n",
    "FEATURES = len(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:17:07.961569Z",
     "start_time": "2020-04-09T06:17:07.954577Z"
    }
   },
   "outputs": [],
   "source": [
    "def tf_dataset_gen(x, y, xt, yt, BUFFER_SIZE, BATCH_SIZE, gpu=False, multiplier=0, cache=False):\n",
    "    if gpu == True:\n",
    "        BATCH_SIZE = BATCH_SIZE * multiplier\n",
    "        print(\"GPU: ON\")\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x.values, y.values)).shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((xt.values, yt.values)).batch(BATCH_SIZE)\n",
    "    if cache == True: # Ensures loader doesnt re-read data at each epoch.\n",
    "        train_dataset = train_dataset.cache()\n",
    "        test_dataset = test_dataset.cache()\n",
    "    STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
    "    print(\"BATCH SIZE: \", BATCH_SIZE)\n",
    "    print(\"STEPS PER EPOCH: \", STEPS_PER_EPOCH)\n",
    "    return train_dataset, test_dataset, STEPS_PER_EPOCH, BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:17:08.743461Z",
     "start_time": "2020-04-09T06:17:08.539419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH SIZE:  500\n",
      "STEPS PER EPOCH:  2\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, STEPS_PER_EPOCH_CPU, BATCH_SIZE_CPU = tf_dataset_gen(\n",
    "    x_train, y_train, x_test, y_test, BUFFER_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:19:00.953222Z",
     "start_time": "2020-04-09T06:19:00.947220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: ON\n",
      "BATCH SIZE:  400\n",
      "STEPS PER EPOCH:  3\n"
     ]
    }
   ],
   "source": [
    "train_dataset_gpu, test_dataset_gpu, STEPS_PER_EPOCH_GPU, BATCH_SIZE_GPU = tf_dataset_gen(\n",
    "    x_train, y_train, x_test, y_test, BUFFER_SIZE, 200, gpu=True, multiplier=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:17:13.454058Z",
     "start_time": "2020-04-09T06:17:13.451061Z"
    }
   },
   "outputs": [],
   "source": [
    "size_histories = {}\n",
    "size_histories_gpu = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:29:10.541759Z",
     "start_time": "2020-04-09T06:29:10.539757Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with cpu_strategy.scope():\n",
    "#     tiny_model = tf.keras.Sequential([\n",
    "#         layers.Dense(16, activation='elu', input_shape=(FEATURES,)),\n",
    "#         layers.Dense(1)])\n",
    "#     size_histories['Tiny_CPU'] = compile_and_fit(tiny_model, 'sizes/Tiny_CPU', train_dataset, \n",
    "#                                                  test_dataset, STEPS_PER_EPOCH_CPU, max_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:19:11.285682Z",
     "start_time": "2020-04-09T06:19:04.347580Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 16)                784       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 801\n",
      "Trainable params: 801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:12.8358,  mae:0.8951,  mse:12.8358,  val_loss:1.9230,  val_mae:0.7191,  val_mse:1.9230,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:9.0198,  mae:0.7339,  mse:9.0198,  val_loss:1.1391,  val_mae:0.6192,  val_mse:1.1391,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:8.8378,  mae:0.7216,  mse:8.8378,  val_loss:1.1663,  val_mae:0.5999,  val_mse:1.1663,  \n",
      ".................................................................................Wall time: 6.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# with gpu_strategy.scope():\n",
    "with single_gpu_strategy.scope():\n",
    "    tiny_model = tf.keras.Sequential([layers.Dense(16, activation='elu', input_shape=(FEATURES,)), \n",
    "                                      layers.Dense(1)])\n",
    "    size_histories['Tiny_GPU'] = compile_and_fit(tiny_model, 'sizes/Tiny_GPU', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, \n",
    "                                                      STEPS_PER_EPOCH_GPU, max_epochs=5000, DECAY_EPOCHS=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:29:05.894251Z",
     "start_time": "2020-04-09T06:29:05.892228Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with gpu_strategy.scope():\n",
    "#     tiny_model = tf.keras.Sequential([layers.Dense(16, activation='elu', input_shape=(FEATURES,)), \n",
    "#                                       layers.Dense(1)])\n",
    "#     size_histories['Tiny_GPU_500'] = compile_and_fit(tiny_model, 'sizes/Tiny_GPU_500', \n",
    "#                                                  train_dataset_gpu, test_dataset_gpu, \n",
    "#                                                       STEPS_PER_EPOCH_GPU, max_epochs=5000, DECAY_EPOCHS=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:29:34.894329Z",
     "start_time": "2020-04-09T06:29:34.892320Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with gpu_strategy.scope():\n",
    "#     tiny_model = tf.keras.Sequential([layers.Dense(16, activation='elu', input_shape=(FEATURES,)), \n",
    "#                                       layers.Dense(1)])\n",
    "#     size_histories['Tiny_GPU_15000'] = compile_and_fit(tiny_model, 'sizes/Tiny_GPU_500', \n",
    "#                                                  train_dataset_gpu, test_dataset_gpu, \n",
    "#                                                       STEPS_PER_EPOCH_GPU, max_epochs=15000, DECAY_EPOCHS=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:30:25.180437Z",
     "start_time": "2020-04-09T06:29:56.068263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 16)                784       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,161\n",
      "Trainable params: 2,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:12.1007,  mae:0.7035,  mse:12.1007,  val_loss:1.5618,  val_mae:0.5744,  val_mse:1.5618,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.7910,  mae:0.4576,  mse:0.7910,  val_loss:1.0203,  val_mae:0.4669,  val_mse:1.0203,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:4.7772,  mae:0.4245,  mse:4.7772,  val_loss:0.8837,  val_mae:0.4215,  val_mse:0.8837,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.5158,  mae:0.3450,  mse:0.5158,  val_loss:0.8751,  val_mae:0.4079,  val_mse:0.8751,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.5852,  mae:0.3941,  mse:0.5852,  val_loss:0.8642,  val_mae:0.4088,  val_mse:0.8642,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:4.7590,  mae:0.3984,  mse:4.7590,  val_loss:0.8640,  val_mae:0.3869,  val_mse:0.8640,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:4.6794,  mae:0.4026,  mse:4.6794,  val_loss:0.8628,  val_mae:0.3869,  val_mse:0.8628,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:4.6799,  mae:0.4064,  mse:4.6799,  val_loss:0.8461,  val_mae:0.4101,  val_mse:0.8461,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:4.7607,  mae:0.3992,  mse:4.7607,  val_loss:0.8451,  val_mae:0.3863,  val_mse:0.8451,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:4.7633,  mae:0.4215,  mse:4.7633,  val_loss:0.8444,  val_mae:0.4070,  val_mse:0.8444,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:4.6921,  mae:0.3945,  mse:4.6921,  val_loss:0.8386,  val_mae:0.3961,  val_mse:0.8386,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, loss:4.7611,  mae:0.4108,  mse:4.7611,  val_loss:0.8405,  val_mae:0.3941,  val_mse:0.8405,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, loss:4.7648,  mae:0.4091,  mse:4.7648,  val_loss:0.8419,  val_mae:0.4061,  val_mse:0.8419,  \n",
      ".................Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with single_gpu_strategy.scope():\n",
    "    tiny_model = tf.keras.Sequential([layers.Dense(16, activation='elu', input_shape=(FEATURES,)), \n",
    "                                      layers.Dense(16, activation='elu'),\n",
    "                                      layers.Dense(16, activation='elu'),\n",
    "                                      layers.Dense(16, activation='elu'),\n",
    "                                      layers.Dense(16, activation='elu'),\n",
    "                                      layers.Dense(16, activation='elu'),\n",
    "                                      layers.Dense(1)])\n",
    "    size_histories['Tiny_GPU_exp'] = compile_and_fit(tiny_model, 'sizes/Tiny_GPU_exp', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, \n",
    "                                                      STEPS_PER_EPOCH_GPU, max_epochs=15000, DECAY_EPOCHS=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:31:18.225448Z",
     "start_time": "2020-04-09T06:31:09.700676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 112)               5488      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 113       \n",
      "=================================================================\n",
      "Total params: 182,785\n",
      "Trainable params: 182,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:7.8184,  mae:0.8434,  mse:7.8184,  val_loss:1.3108,  val_mae:0.5722,  val_mse:1.3108,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:4.7801,  mae:0.4105,  mse:4.7801,  val_loss:2.5322,  val_mae:0.4901,  val_mse:2.5322,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:4.7524,  mae:0.4060,  mse:4.7524,  val_loss:2.4176,  val_mae:0.4741,  val_mse:2.4176,  \n",
      ".......................................Wall time: 8.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with single_gpu_strategy.scope():\n",
    "    tiny_model = tf.keras.Sequential([layers.Dense(112, activation='elu', input_shape=(FEATURES,)), \n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(112, activation='elu'),\n",
    "                                      layers.Dense(1)])\n",
    "    size_histories['Tiny_GPU_exp112'] = compile_and_fit(tiny_model, 'sizes/Tiny_GPU_exp112', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, \n",
    "                                                      STEPS_PER_EPOCH_GPU, max_epochs=15000, DECAY_EPOCHS=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:32:20.991233Z",
     "start_time": "2020-04-09T06:32:09.062479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 112)               5488      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 112)               12656     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 113       \n",
      "=================================================================\n",
      "Total params: 182,785\n",
      "Trainable params: 182,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:7.8891,  mae:0.6731,  mse:7.8891,  val_loss:1.9351,  val_mae:0.5768,  val_mse:1.9351,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:4.6576,  mae:0.3656,  mse:4.6576,  val_loss:1.0578,  val_mae:0.3995,  val_mse:1.0578,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:4.7307,  mae:0.4117,  mse:4.7307,  val_loss:0.9819,  val_mae:0.3641,  val_mse:0.9819,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:4.7117,  mae:0.3903,  mse:4.7117,  val_loss:1.0710,  val_mae:0.4066,  val_mse:1.0710,  \n",
      "...............................................................Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with single_gpu_strategy.scope():\n",
    "    tiny_model = tf.keras.Sequential([layers.Dense(112, activation='relu', input_shape=(FEATURES,)), \n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(112, activation='relu'),\n",
    "                                      layers.Dense(1)])\n",
    "    size_histories['Tiny_GPU_exp_relu'] = compile_and_fit(tiny_model, 'sizes/Tiny_GPU_exp_relu', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, \n",
    "                                                      STEPS_PER_EPOCH_GPU, max_epochs=15000, DECAY_EPOCHS=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,10))\n",
    "# plotter = tfdocs.plots.HistoryPlotter(metric='mae', smoothing_std=5)\n",
    "# plotter.plot(size_histories)\n",
    "# plt.ylim()\n",
    "# plt.ylabel('MAE [MeV]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:32:59.489809Z",
     "start_time": "2020-04-09T06:32:53.603915Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 64)                3136      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 11,521\n",
      "Trainable params: 11,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:12.1501,  mae:0.8857,  mse:12.1501,  val_loss:1.7294,  val_mae:0.6091,  val_mse:1.7294,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:5.1973,  mae:0.6206,  mse:5.1973,  val_loss:1.2343,  val_mae:0.4995,  val_mse:1.2343,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:4.8017,  mae:0.4096,  mse:4.8017,  val_loss:1.1738,  val_mae:0.4534,  val_mse:1.1738,  \n",
      ".........Wall time: 5.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with single_gpu_strategy.scope():\n",
    "    medium_model = tf.keras.Sequential([\n",
    "        layers.Dense(64, activation='elu', input_shape=(FEATURES,)),\n",
    "        layers.Dense(64, activation='elu'),\n",
    "        layers.Dense(64, activation='elu'),\n",
    "        layers.Dense(1)])\n",
    "    size_histories['Medium_GPU'] = compile_and_fit(medium_model, 'sizes/Medium_GPU', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, STEPS_PER_EPOCH_GPU, max_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:33:21.204954Z",
     "start_time": "2020-04-09T06:33:11.812557Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 512)               25088     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 813,569\n",
      "Trainable params: 813,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:12.8413,  mae:1.3320,  mse:12.8413,  val_loss:1.6885,  val_mae:0.8537,  val_mse:1.6885,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:4.7239,  mae:0.4257,  mse:4.7239,  val_loss:1.2439,  val_mae:0.4223,  val_mse:1.2439,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:4.7900,  mae:0.4739,  mse:4.7900,  val_loss:1.3050,  val_mae:0.6071,  val_mse:1.3050,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:4.8057,  mae:0.5884,  mse:4.8057,  val_loss:1.4842,  val_mae:0.3960,  val_mse:1.4842,  \n",
      ".........................................................Wall time: 9.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with single_gpu_strategy.scope():\n",
    "    large_model = tf.keras.Sequential([\n",
    "        layers.Dense(512, activation='elu', input_shape=(FEATURES,)),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dense(1)])\n",
    "    size_histories['Large_GPU'] = compile_and_fit(large_model, 'sizes/Large_GPU', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, STEPS_PER_EPOCH_GPU, max_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:33:39.477934Z",
     "start_time": "2020-04-09T06:33:39.475933Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,10))\n",
    "# plotter.plot(size_histories)\n",
    "# a = plt.xscale('log')\n",
    "# plt.xlim([5, max(plt.xlim())])\n",
    "# # plt.ylim([0.5, 0.7])\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel(\"Epochs [Log Scale]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Regularization\n",
    "\n",
    "As we know from Occam's Razor Principle the simplest one is the most likeley to be correct (the one with least amount of assumptions). Similar for neural networks, there will always be multiple models and therefore weights that can explain data. A simple model in this context is a model where the distribution of parameter values has less entropy. A common way to mitigate overfitting is to put constraints on the complexity of the NN by forcing weights to take small values which makes the distribution of such values more regular (weight regularization). This can be done by adding to the loss functionof the network a cost associated with having large weights. This costs can be:\n",
    "- L1 Regularization: cost added proportional to the absolute value of the weights coefficients (L1 Norm). It pushes weights towards exactly 0 encouraging sparsity.\n",
    "- L2 Regularization: proportional to the square of the value of the weights coefficients (L2 Norm). It is also called weight decay in NN context. It penalizes weight parameters without making them sparse since the weights go to 0 but are not 0. More common of the two. \n",
    "\n",
    "The `regularizers.l2(VALUE)` will make that every coefficient in the weight matrix of the layer will add VALUE * $weight_coefficients_value**2$ to the total loss of the network. In binary classification problems we monitor binary crossentropy since it doesnt have this regularization component mixed in.\n",
    "\n",
    "Check if l2 is better than large at overfitting (same parameters)?\n",
    "\n",
    "Dropout one of the most effective and most commonly used for NN. It is based on the fact that individual nodes in the N cannot rely on the output of the otherse, each node must output features that are useful on their own. The drooput layer randomly droppes out (set to zero) a number of output features of the layer during training. Let's say a given layer would normally have returned a vector [0.2, 0.5, 1.3, 0.8, 1.1] for a given input sample during training; after applying dropout, this vector will have a few zero entries distributed at random, e.g. [0, 0.5, 1.3, 0, 1.1]. The dropout rate is the fraction of features that are zeroed out (between 0.2 to 0.5 usually). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:33:50.317663Z",
     "start_time": "2020-04-09T06:33:50.315808Z"
    }
   },
   "outputs": [],
   "source": [
    "regularizer_histories = {}\n",
    "# regularizer_histories['Tiny_GPU_1000'] = size_histories['Tiny_GPU_1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:34:12.671764Z",
     "start_time": "2020-04-09T06:33:59.084531Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 512)               25088     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 813,569\n",
      "Trainable params: 813,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:12.3083,  mae:1.1600,  mse:10.6891,  val_loss:4.1694,  val_mae:1.2044,  val_mse:2.5574,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:1.7157,  mae:0.3493,  mse:0.5316,  val_loss:2.2496,  val_mae:0.4938,  val_mse:1.0685,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:5.6347,  mae:0.4518,  mse:4.7763,  val_loss:2.2269,  val_mae:0.4775,  val_mse:1.3700,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:5.4110,  mae:0.3722,  mse:4.7717,  val_loss:2.2538,  val_mae:0.4625,  val_mse:1.6159,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:5.2754,  mae:0.4997,  mse:4.7834,  val_loss:2.4560,  val_mae:0.4291,  val_mse:1.9647,  \n",
      "..................................................................................Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with single_gpu_strategy.scope():\n",
    "    l2_model = tf.keras.Sequential([\n",
    "        layers.Dense(512, activation='elu',\n",
    "                     kernel_regularizer=regularizers.l2(0.001),\n",
    "                     input_shape=(FEATURES,)),\n",
    "        layers.Dense(512, activation='elu',\n",
    "                     kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dense(512, activation='elu',\n",
    "                     kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dense(512, activation='elu',\n",
    "                     kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    regularizer_histories['l2'] = compile_and_fit(l2_model, 'regularizers/l2', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, STEPS_PER_EPOCH_GPU, max_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:34:45.784625Z",
     "start_time": "2020-04-09T06:34:37.085154Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 512)               25088     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 813,569\n",
      "Trainable params: 813,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:10.9129,  mae:1.2084,  mse:10.9129,  val_loss:1.2723,  val_mae:0.5676,  val_mse:1.2723,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:5.7058,  mae:0.8131,  mse:5.7058,  val_loss:1.5855,  val_mae:0.4244,  val_mse:1.5855,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:5.2180,  mae:0.6072,  mse:5.2180,  val_loss:1.5653,  val_mae:0.4155,  val_mse:1.5653,  \n",
      ".................................................................................Wall time: 8.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with single_gpu_strategy.scope():\n",
    "    dropout_model = tf.keras.Sequential([\n",
    "        layers.Dense(512, activation='elu', input_shape=(FEATURES,)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    regularizer_histories['dropout'] = compile_and_fit(dropout_model, 'regularizers/dropout', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, STEPS_PER_EPOCH_GPU, max_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:35:08.069790Z",
     "start_time": "2020-04-09T06:34:58.990223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 512)               25088     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 813,569\n",
      "Trainable params: 813,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:10.8725,  mae:1.0601,  mse:10.7102,  val_loss:1.4368,  val_mae:0.6113,  val_mse:1.2747,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:5.8311,  mae:0.7554,  mse:5.6646,  val_loss:1.8639,  val_mae:0.4692,  val_mse:1.6974,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:5.3881,  mae:0.6184,  mse:5.2199,  val_loss:2.2240,  val_mae:0.4907,  val_mse:2.0558,  \n",
      ".......................................................................Wall time: 9.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with single_gpu_strategy.scope():\n",
    "    combined_model = tf.keras.Sequential([\n",
    "        layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                     activation='elu', input_shape=(FEATURES,)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                     activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                     activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                     activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    regularizer_histories['combined'] = compile_and_fit(combined_model, 'regularizers/combined', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, STEPS_PER_EPOCH_GPU, max_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:35:36.404581Z",
     "start_time": "2020-04-09T06:35:25.485028Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 1000)              49000     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 3,053,001\n",
      "Trainable params: 3,053,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:8.6765,  mae:1.5316,  mse:8.3674,  val_loss:3.0104,  val_mae:1.2369,  val_mse:2.7014,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:1.2850,  mae:0.6033,  mse:0.9625,  val_loss:1.3692,  val_mae:0.4143,  val_mse:1.0468,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:5.4789,  mae:0.5614,  mse:5.1588,  val_loss:2.1315,  val_mae:0.4954,  val_mse:1.8114,  \n",
      "................................................................................................Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with single_gpu_strategy.scope():\n",
    "    combined_model = tf.keras.Sequential([\n",
    "        layers.Dense(1000, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                     activation='elu', input_shape=(FEATURES,)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1000, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                     activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1000, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                     activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1000, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                     activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    regularizer_histories['combined_1000'] = compile_and_fit(combined_model, 'regularizers/combined_1000', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, STEPS_PER_EPOCH_GPU, max_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:36:07.518219Z",
     "start_time": "2020-04-09T06:36:07.516230Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,10))\n",
    "# plotter.plot(regularizer_histories)\n",
    "# a = plt.xscale('log')\n",
    "# plt.xlim([2, max(plt.xlim())])\n",
    "# # plt.ylim([0.5, 0.7])\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel(\"Epochs [Log Scale]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 512)               2560      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 2,366,977\n",
      "Trainable params: 2,366,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.152171). Check your callbacks.\n",
      "\n",
      "Epoch: 0, loss:6.1826,  mae:1.8188,  mse:6.1826,  val_loss:5.7414,  val_mae:2.0655,  val_mse:6.6412,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:1.2400,  mae:0.8470,  mse:1.2400,  val_loss:1.0483,  val_mae:0.8415,  val_mse:1.2293,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:1.1881,  mae:0.8331,  mse:1.1881,  val_loss:0.9534,  val_mae:0.8131,  val_mse:1.1239,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:1.1189,  mae:0.8170,  mse:1.1189,  val_loss:0.9398,  val_mae:0.8007,  val_mse:1.1060,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:1.0868,  mae:0.8056,  mse:1.0868,  val_loss:0.9263,  val_mae:0.7947,  val_mse:1.0773,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:1.0485,  mae:0.7881,  mse:1.0485,  val_loss:0.8737,  val_mae:0.7931,  val_mse:1.0337,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:1.0356,  mae:0.7857,  mse:1.0356,  val_loss:0.8379,  val_mae:0.7600,  val_mse:0.9710,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.9961,  mae:0.7769,  mse:0.9961,  val_loss:0.8383,  val_mae:0.7743,  val_mse:1.0004,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.9967,  mae:0.7687,  mse:0.9967,  val_loss:0.8476,  val_mae:0.7645,  val_mse:0.9917,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.9431,  mae:0.7484,  mse:0.9431,  val_loss:0.7855,  val_mae:0.7340,  val_mse:0.9148,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.8934,  mae:0.7356,  mse:0.8934,  val_loss:0.7116,  val_mae:0.6888,  val_mse:0.8248,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, loss:0.8432,  mae:0.7105,  mse:0.8432,  val_loss:0.7137,  val_mae:0.6945,  val_mse:0.8331,  \n",
      "....................................................................................................\n",
      "Epoch: 1200, loss:0.8540,  mae:0.7135,  mse:0.8540,  val_loss:0.7168,  val_mae:0.6885,  val_mse:0.8324,  \n",
      "....................................................................................................\n",
      "Epoch: 1300, loss:0.8213,  mae:0.6999,  mse:0.8213,  val_loss:0.6586,  val_mae:0.6654,  val_mse:0.7741,  \n",
      "....................................................................................................\n",
      "Epoch: 1400, loss:0.8146,  mae:0.6960,  mse:0.8146,  val_loss:0.6604,  val_mae:0.6739,  val_mse:0.7747,  \n",
      "....................................................................................................\n",
      "Epoch: 1500, loss:0.8210,  mae:0.6983,  mse:0.8210,  val_loss:0.6966,  val_mae:0.6861,  val_mse:0.8145,  \n",
      "....................................................................................................\n",
      "Epoch: 1600, loss:0.7841,  mae:0.6853,  mse:0.7841,  val_loss:0.6373,  val_mae:0.6630,  val_mse:0.7530,  \n",
      "....................................................................................................\n",
      "Epoch: 1700, loss:0.7812,  mae:0.6807,  mse:0.7812,  val_loss:0.6509,  val_mae:0.6653,  val_mse:0.7635,  \n",
      "....................................................................................................\n",
      "Epoch: 1800, loss:0.7798,  mae:0.6786,  mse:0.7798,  val_loss:0.6219,  val_mae:0.6585,  val_mse:0.7408,  \n",
      "....................................................................................................\n",
      "Epoch: 1900, loss:0.7488,  mae:0.6727,  mse:0.7488,  val_loss:0.6194,  val_mae:0.6420,  val_mse:0.7273,  \n",
      "......................................Wall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with gpu_strategy.scope():\n",
    "    dropout_model = tf.keras.Sequential([\n",
    "        layers.Dense(512, activation='elu', input_shape=(FEATURES,)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='elu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    regularizer_histories['dropout_3'] = compile_and_fit(dropout_model, 'regularizers/dropout_3', \n",
    "                                                 train_dataset_gpu, test_dataset_gpu, STEPS_PER_EPOCH_GPU, max_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T06:36:17.263414Z",
     "start_time": "2020-04-09T06:36:17.261414Z"
    }
   },
   "outputs": [],
   "source": [
    "# hist = pd.DataFrame(regularizer_histories['l2'].history)\n",
    "# hist['epoch'] = regularizer_histories['l2'].epoch\n",
    "# hist.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook introduced a few techniques to handle a regression problem.\n",
    "\n",
    "* Mean Squared Error (MSE) is a common loss function used for regression problems (different loss functions are used for classification problems).\n",
    "* Similarly, evaluation metrics used for regression differ from classification. A common regression metric is Mean Absolute Error (MAE).\n",
    "* When numeric input data features have values with different ranges, each feature should be scaled independently to the same range.\n",
    "* If there is not much training data, one technique is to prefer a small network with few hidden layers to avoid overfitting.\n",
    "* Early stopping is a useful technique to prevent overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
