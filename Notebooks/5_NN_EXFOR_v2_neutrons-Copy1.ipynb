{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up GPU and ML Management Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:24:17.113602Z",
     "start_time": "2020-07-21T05:24:17.109602Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# If you don't want your script to sync to the cloud\n",
    "os.environ['WANDB_IGNORE_GLOBS'] = \"*.patch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:24:19.278569Z",
     "start_time": "2020-07-21T05:24:18.268168Z"
    }
   },
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:24:21.152839Z",
     "start_time": "2020-07-21T05:24:20.084071Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from joblib import dump, load\n",
    "from  IPython import display\n",
    "import shutil\n",
    "import tempfile\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "# This allows us to import the nucml utilities\n",
    "sys.path.append(\"..\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:24:23.383263Z",
     "start_time": "2020-07-21T05:24:21.154341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish importing scripts.\n"
     ]
    }
   ],
   "source": [
    "import nucml.exfor.data_utilities as exfor_utils\n",
    "import nucml.endf.data_utilities as endf_utils\n",
    "import nucml.plot.plotting_utilities as plot_utils\n",
    "import nucml.datasets as nuc_data\n",
    "import nucml.ace.data_utilities as ace_utils\n",
    "import nucml.model.model_building_nn as model_tools\n",
    "importlib.reload(model_tools)\n",
    "importlib.reload(exfor_utils)\n",
    "importlib.reload(endf_utils)\n",
    "importlib.reload(plot_utils)\n",
    "importlib.reload(nuc_data)\n",
    "importlib.reload(ace_utils)\n",
    "print(\"Finish importing scripts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T18:46:39.892458Z",
     "start_time": "2020-07-16T18:46:39.886957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T21:05:24.150569Z",
     "start_time": "2020-07-15T21:04:24.060334Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir wandb --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading EXFOR data (Energy in eV and Data in b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:03.620808Z",
     "start_time": "2020-07-21T05:25:03.263092Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\ML_Data\\EXFOR_neutrons\\EXFOR_neutrons_MF3_AME_no_NaNRaw.csv\n",
      "Reading data into dataframe...\n",
      " MODE: neutrons\n",
      " LOW ENERGY: True\n",
      " LOG: True\n",
      " BASIC: 1\n",
      " SCALER: std\n",
      "Data read into dataframe with shape:  (4184245, 19)\n",
      "Dropping unnecessary features and one-hot encoding categorical columns...\n",
      "Splitting dataset into training and testing...\n",
      "Normalizing dataset...\n",
      "Fitting new scaler.\n",
      "Finished. Resulting dataset has shape  (4184245, 58) \n",
      "Training and Testing dataset shapes are (3765820, 57) and (418425, 57) respesctively.\n"
     ]
    }
   ],
   "source": [
    "# df, x_train, x_test, y_train, y_test, to_scale, scaler = nuc_data.load_exfor(log=True, basic=1, num=True, low_en=True, scaler_dir='../ML_Data/Models/NN/scaler_ext.pkl')\n",
    "df, x_train, x_test, y_train, y_test, to_scale, scaler = nuc_data.load_exfor(\n",
    "    log=True, basic=1, num=True, low_en=True, scaling_type=\"std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:25:01.334264Z",
     "start_time": "2020-07-21T05:24:57.074Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_saving_dir = '../ML_Data/Models/NN/'\n",
    "\n",
    "dump(scaler, open(os.path.join(nn_saving_dir, 'scaler_ext_std.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Chlorine (n,p) and U-233(n,f) Data for Visualization\n",
    "\n",
    "The model will be trained in the entire data therefore getting the total MSE. As an example, we will see the model predictions for both the mentioned reactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:04.146900Z",
     "start_time": "2020-07-21T05:26:03.622307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting samples from dataframe.\n",
      "Scaling dataset...\n",
      "EXFOR extracted DataFrame has shape:  (215, 58)\n",
      "Extracting samples from dataframe.\n",
      "Scaling dataset...\n",
      "EXFOR extracted DataFrame has shape:  (40108, 58)\n",
      "Extracting samples from dataframe.\n",
      "Scaling dataset...\n",
      "EXFOR extracted DataFrame has shape:  (94567, 58)\n",
      "Extracting samples from dataframe.\n",
      "EXFOR extracted DataFrame has shape:  (33384, 58)\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\"nat_iso\": \"I\", \"one_hot\": True, \"scale\": True, \"scaler\": scaler, \"to_scale\": to_scale}\n",
    "\n",
    "chlorine_35_np = exfor_utils.load_exfor_samples(df, 17, 35, \"MT_103\", **kwargs)\n",
    "uranium_235_nt = exfor_utils.load_exfor_samples(df, 92, 235, \"MT_1\", **kwargs)\n",
    "uranium_233_nf = exfor_utils.load_exfor_samples(df, 92, 233, \"MT_18\", **kwargs)\n",
    "uranium_233_nt = exfor_utils.load_exfor_samples(df, 92, 233, \"MT_1\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:05.346111Z",
     "start_time": "2020-07-21T05:26:04.148400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting samples from dataframe.\n",
      "Scaling dataset...\n",
      "EXFOR extracted DataFrame has shape:  (468123, 58)\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\"nat_iso\": \"I\", \"one_hot\": True, \"scale\": True, \"scaler\": scaler, \"to_scale\": to_scale}\n",
    "uranium = exfor_utils.load_exfor_element(df, 92, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newly Measured Chlorine (n,p) Unseen Data \n",
    "\n",
    "These data points are not in the current EXFOR data package and will be used to test the new modeling capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:05.458631Z",
     "start_time": "2020-07-21T05:26:05.347611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting samples from dataframe.\n",
      "EXFOR extracted DataFrame has shape:  (215, 58)\n",
      "Expanded Dataset has shape:  (12, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy</th>\n",
       "      <th>Data</th>\n",
       "      <th>Target_Protons</th>\n",
       "      <th>Target_Neutrons</th>\n",
       "      <th>Target_Mass_Number</th>\n",
       "      <th>Target_Radius</th>\n",
       "      <th>Target_Neut_Rad_Ratio</th>\n",
       "      <th>Target_Mass_Excess</th>\n",
       "      <th>Target_Binding_Energy</th>\n",
       "      <th>Target_B_Decay_Energy</th>\n",
       "      <th>Target_Atomic_Mass_Micro</th>\n",
       "      <th>Target_S(2n)</th>\n",
       "      <th>Target_S(n)</th>\n",
       "      <th>Target_S(p)</th>\n",
       "      <th>MT_1</th>\n",
       "      <th>MT_102</th>\n",
       "      <th>MT_16</th>\n",
       "      <th>MT_17</th>\n",
       "      <th>MT_2</th>\n",
       "      <th>MT_3</th>\n",
       "      <th>MT_4</th>\n",
       "      <th>MT_101</th>\n",
       "      <th>MT_103</th>\n",
       "      <th>MT_104</th>\n",
       "      <th>MT_41</th>\n",
       "      <th>MT_9000</th>\n",
       "      <th>MT_105</th>\n",
       "      <th>MT_32</th>\n",
       "      <th>MT_51</th>\n",
       "      <th>MT_33</th>\n",
       "      <th>MT_107</th>\n",
       "      <th>MT_24</th>\n",
       "      <th>MT_155</th>\n",
       "      <th>MT_158</th>\n",
       "      <th>MT_159</th>\n",
       "      <th>MT_108</th>\n",
       "      <th>MT_29</th>\n",
       "      <th>MT_1108</th>\n",
       "      <th>MT_113</th>\n",
       "      <th>MT_106</th>\n",
       "      <th>MT_22</th>\n",
       "      <th>MT_1003</th>\n",
       "      <th>MT_9001</th>\n",
       "      <th>MT_28</th>\n",
       "      <th>MT_111</th>\n",
       "      <th>MT_203</th>\n",
       "      <th>MT_2103</th>\n",
       "      <th>MT_112</th>\n",
       "      <th>MT_37</th>\n",
       "      <th>MT_161</th>\n",
       "      <th>MT_152</th>\n",
       "      <th>MT_153</th>\n",
       "      <th>MT_18</th>\n",
       "      <th>MT_160</th>\n",
       "      <th>Frame_L</th>\n",
       "      <th>Frame_C</th>\n",
       "      <th>Target_Flag_I</th>\n",
       "      <th>Target_Flag_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.383815</td>\n",
       "      <td>-1.779892</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>4.088833</td>\n",
       "      <td>0.195655</td>\n",
       "      <td>-29013.528</td>\n",
       "      <td>8520.278</td>\n",
       "      <td>-5966.243</td>\n",
       "      <td>3.496885e+07</td>\n",
       "      <td>24152.83</td>\n",
       "      <td>12644.76</td>\n",
       "      <td>6370.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.383815</td>\n",
       "      <td>-1.707744</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>4.088833</td>\n",
       "      <td>0.195655</td>\n",
       "      <td>-29013.528</td>\n",
       "      <td>8520.278</td>\n",
       "      <td>-5966.243</td>\n",
       "      <td>3.496885e+07</td>\n",
       "      <td>24152.83</td>\n",
       "      <td>12644.76</td>\n",
       "      <td>6370.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.401401</td>\n",
       "      <td>-1.583359</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>4.088833</td>\n",
       "      <td>0.195655</td>\n",
       "      <td>-29013.528</td>\n",
       "      <td>8520.278</td>\n",
       "      <td>-5966.243</td>\n",
       "      <td>3.496885e+07</td>\n",
       "      <td>24152.83</td>\n",
       "      <td>12644.76</td>\n",
       "      <td>6370.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.401401</td>\n",
       "      <td>-1.590067</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>4.088833</td>\n",
       "      <td>0.195655</td>\n",
       "      <td>-29013.528</td>\n",
       "      <td>8520.278</td>\n",
       "      <td>-5966.243</td>\n",
       "      <td>3.496885e+07</td>\n",
       "      <td>24152.83</td>\n",
       "      <td>12644.76</td>\n",
       "      <td>6370.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.411620</td>\n",
       "      <td>-1.350665</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>4.088833</td>\n",
       "      <td>0.195655</td>\n",
       "      <td>-29013.528</td>\n",
       "      <td>8520.278</td>\n",
       "      <td>-5966.243</td>\n",
       "      <td>3.496885e+07</td>\n",
       "      <td>24152.83</td>\n",
       "      <td>12644.76</td>\n",
       "      <td>6370.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Energy      Data  Target_Protons  Target_Neutrons  Target_Mass_Number  \\\n",
       "0  6.383815 -1.779892              17               18                  35   \n",
       "1  6.383815 -1.707744              17               18                  35   \n",
       "2  6.401401 -1.583359              17               18                  35   \n",
       "3  6.401401 -1.590067              17               18                  35   \n",
       "4  6.411620 -1.350665              17               18                  35   \n",
       "\n",
       "   Target_Radius  Target_Neut_Rad_Ratio  Target_Mass_Excess  \\\n",
       "0       4.088833               0.195655          -29013.528   \n",
       "1       4.088833               0.195655          -29013.528   \n",
       "2       4.088833               0.195655          -29013.528   \n",
       "3       4.088833               0.195655          -29013.528   \n",
       "4       4.088833               0.195655          -29013.528   \n",
       "\n",
       "   Target_Binding_Energy  Target_B_Decay_Energy  Target_Atomic_Mass_Micro  \\\n",
       "0               8520.278              -5966.243              3.496885e+07   \n",
       "1               8520.278              -5966.243              3.496885e+07   \n",
       "2               8520.278              -5966.243              3.496885e+07   \n",
       "3               8520.278              -5966.243              3.496885e+07   \n",
       "4               8520.278              -5966.243              3.496885e+07   \n",
       "\n",
       "   Target_S(2n)  Target_S(n)  Target_S(p)  MT_1  MT_102  MT_16  MT_17  MT_2  \\\n",
       "0      24152.83     12644.76      6370.81     0       0      0      0     0   \n",
       "1      24152.83     12644.76      6370.81     0       0      0      0     0   \n",
       "2      24152.83     12644.76      6370.81     0       0      0      0     0   \n",
       "3      24152.83     12644.76      6370.81     0       0      0      0     0   \n",
       "4      24152.83     12644.76      6370.81     0       0      0      0     0   \n",
       "\n",
       "   MT_3  MT_4  MT_101  MT_103  MT_104  MT_41  MT_9000  MT_105  MT_32  MT_51  \\\n",
       "0     0     0       0       1       0      0        0       0      0      0   \n",
       "1     0     0       0       1       0      0        0       0      0      0   \n",
       "2     0     0       0       1       0      0        0       0      0      0   \n",
       "3     0     0       0       1       0      0        0       0      0      0   \n",
       "4     0     0       0       1       0      0        0       0      0      0   \n",
       "\n",
       "   MT_33  MT_107  MT_24  MT_155  MT_158  MT_159  MT_108  MT_29  MT_1108  \\\n",
       "0      0       0      0       0       0       0       0      0        0   \n",
       "1      0       0      0       0       0       0       0      0        0   \n",
       "2      0       0      0       0       0       0       0      0        0   \n",
       "3      0       0      0       0       0       0       0      0        0   \n",
       "4      0       0      0       0       0       0       0      0        0   \n",
       "\n",
       "   MT_113  MT_106  MT_22  MT_1003  MT_9001  MT_28  MT_111  MT_203  MT_2103  \\\n",
       "0       0       0      0        0        0      0       0       0        0   \n",
       "1       0       0      0        0        0      0       0       0        0   \n",
       "2       0       0      0        0        0      0       0       0        0   \n",
       "3       0       0      0        0        0      0       0       0        0   \n",
       "4       0       0      0        0        0      0       0       0        0   \n",
       "\n",
       "   MT_112  MT_37  MT_161  MT_152  MT_153  MT_18  MT_160  Frame_L  Frame_C  \\\n",
       "0       0      0       0       0       0      0       0        1        0   \n",
       "1       0      0       0       0       0      0       0        1        0   \n",
       "2       0      0       0       0       0      0       0        1        0   \n",
       "3       0      0       0       0       0      0       0        1        0   \n",
       "4       0      0       0       0       0      0       0        1        0   \n",
       "\n",
       "   Target_Flag_I  Target_Flag_N  \n",
       "0              1              0  \n",
       "1              1              0  \n",
       "2              1              0  \n",
       "3              1              0  \n",
       "4              1              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cl_data_kwargs = {\"Z\":17, \"A\":35, \"MT\":\"MT_103\", \"log\":True, \"scale\":False, \"scaler\":scaler, \"to_scale\":to_scale}\n",
    "new_cl_data = exfor_utils.load_exfor_newdata(\"../EXFOR/New_Data/Chlorine_Data/new_cl_np.csv\", df, **new_cl_data_kwargs)\n",
    "new_cl_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENDF Evaluation Cross Section Data for Chlorine (n,p) Reaction\n",
    "\n",
    "These data points will serve to plot the current ENDFb5 data and compare it to the newly measured points along with the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:05.714175Z",
     "start_time": "2020-07-21T05:26:05.460130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\ML_Data\\ENDF_neutrons\\Cl035\\endfb8.0\\tables\\xs\\n-Cl035-MT103.endfb8.0\n",
      "Converting MeV to eV...\n",
      "Convering mb to b...\n",
      "Finish reading ENDF data with shape:  (8791, 2)\n",
      "C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\ML_Data\\ENDF_neutrons\\U233\\endfb8.0\\tables\\xs\\n-U233-MT018.endfb8.0\n",
      "Converting MeV to eV...\n",
      "Convering mb to b...\n",
      "Finish reading ENDF data with shape:  (15345, 2)\n",
      "C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\ML_Data\\ENDF_neutrons\\Cl037\\endfb8.0\\tables\\xs\\n-Cl037-MT102.endfb8.0\n",
      "Converting MeV to eV...\n",
      "Convering mb to b...\n",
      "Finish reading ENDF data with shape:  (20121, 2)\n",
      "C:\\Users\\Pedro\\Desktop\\ML_Nuclear_Data\\ML_Data\\ENDF_neutrons\\Fe056\\endfb8.0\\tables\\xs\\n-Fe056-MT002.endfb8.0\n",
      "Converting MeV to eV...\n",
      "Convering mb to b...\n",
      "Finish reading ENDF data with shape:  (46021, 2)\n"
     ]
    }
   ],
   "source": [
    "# ENDF EXTRACTION IMPLEMENTED INTO ANOTHER FUNCTION, NO NEED TO OBTAIN MANUALLY IN FUTURE VERSIONS\n",
    "\n",
    "endf_cl = nuc_data.load_endf(\"Cl035\", \"MT103\", log=True)\n",
    "endf_u  = nuc_data.load_endf(\"U233\", \"MT018\", log=True)\n",
    "endf_cl_37 = nuc_data.load_endf(\"Cl037\", \"MT102\", log=True)\n",
    "endf_fe_56 = nuc_data.load_endf(\"Fe056\", \"MT002\", log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading ACE Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:17.673278Z",
     "start_time": "2020-07-21T05:26:05.715176Z"
    }
   },
   "outputs": [],
   "source": [
    "# ACE EXTRACTION IMPLEMENTED INTO ANOTHER FUNCTION, NO NEED TO OBTAIN MANUALLY IN FUTURE VERSIONS\n",
    "\n",
    "ace_u = ace_utils.get_energies(\"92233\", ev=True, log=True)\n",
    "ace_cl = ace_utils.get_energies(\"17035\", ev=True, log=True)\n",
    "ace_cl_37 = ace_utils.get_energies(\"17037\", ev=True, log=True)\n",
    "ace_fe_56 = ace_utils.get_energies(\"26056\", ev=True, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Chlorine and Uranium Prediction Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:17.683281Z",
     "start_time": "2020-07-21T05:26:17.675279Z"
    }
   },
   "outputs": [],
   "source": [
    "order = {\n",
    "    \"3\":\"endf\", \n",
    "    \"1\":\"exfor_ml_original\", \n",
    "    \"2\":\"exfor_ml\", \n",
    "    \"4\":\"exfor_new\"}\n",
    "\n",
    "def run_chlorine(model):\n",
    "    cl_kwargs =  {\"Z\":17, \"A\":35, \"MT\":\"MT_103\", \"clf_type\":\"tf\", \"scaler\":scaler, \"to_scale\":to_scale, \"html\":False,\n",
    "                  \"e_array\":\"ace\", \"log\":True, \"show\":False, \"render\":False, \"save\":False, \"inv_trans\":True}\n",
    "    results_cl = exfor_utils.predicting_nuclear_xs_v2(df, clf=model, new_data=new_cl_data, get_endf=True, **cl_kwargs)\n",
    "    fig = plot_utils.plotly_ml_results(results_cl, show=True)\n",
    "    return fig\n",
    "\n",
    "def run_uranium(model):\n",
    "    u_kwargs =  {\"Z\":92, \"A\":233, \"MT\":\"MT_18\", \"clf_type\":\"tf\", \"scaler\":scaler, \"to_scale\":to_scale, \"html\":False,\n",
    "                  \"e_array\":\"ace\", \"log\":True, \"show\":False, \"render\":False, \"save\":False, \"inv_trans\":True}\n",
    "    results_u = exfor_utils.predicting_nuclear_xs_v2(df, clf=model, get_endf=True, **u_kwargs)\n",
    "    fig = plot_utils.plotly_ml_results(results_u, order_dict=order, show=True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:17.689781Z",
     "start_time": "2020-07-21T05:26:17.685280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:17.872814Z",
     "start_time": "2020-07-21T05:26:17.691781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Output Folder for Checkpoints and Checkpoint Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:17.876814Z",
     "start_time": "2020-07-21T05:26:17.874313Z"
    }
   },
   "outputs": [],
   "source": [
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:17.881815Z",
     "start_time": "2020-07-21T05:26:17.878814Z"
    }
   },
   "outputs": [],
   "source": [
    "# x_train_t = x_train[:10000]\n",
    "# y_train_t = y_train[:10000]\n",
    "# x_test_t = x_test[:10000]\n",
    "# y_test_t = y_test[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:26:17.887317Z",
     "start_time": "2020-07-21T05:26:17.883315Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COMMET_PROJECT_NAME = \"ml-nuclear-data\"\n",
    "WANDB_PROJECT_NAME = \"ml-nuclear-data\"\n",
    "GROUP_NAME = \"EXFOR_Basic_1\" # CHANGED\n",
    "NUM_FEATURES = x_train.shape[1]\n",
    "BATCH_SIZE = 300\n",
    "EPOCHS = 100\n",
    "ACTIVATION = \"relu\"\n",
    "OPTIMIZER = \"ITD\"\n",
    "LR_DECAY_EPOCHS = 10\n",
    "STEPS_PER_EPOCH = len(x_train) // BATCH_SIZE\n",
    "SCALER_TYPE = \"std\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:30:49.803542Z",
     "start_time": "2020-07-21T05:26:40.851546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/pvicentevaldez/ml-nuclear-data\" target=\"_blank\">https://app.wandb.ai/pvicentevaldez/ml-nuclear-data</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/pvicentevaldez/ml-nuclear-data/runs/5_Layers_100_Units_B1_std\" target=\"_blank\">https://app.wandb.ai/pvicentevaldez/ml-nuclear-data/runs/5_Layers_100_Units_B1_std</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (3.1.12) detected. current: 3.1.13 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET ERROR: Failed to log git patch\n",
      "COMET ERROR: Failed to log git patch\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/pedrojrv/ml-nuclear-data/b556a0b45b394bbdb7f8b25cb1135a4d\n",
      "\n",
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n",
      "COMET INFO: Ignoring automatic log_parameter('do_validation') because 'keras:do_validation' is in COMET_LOGGING_PARAMETERS_IGNORE\n",
      "COMET INFO: Ignoring automatic log_metric('batch_batch') because 'keras:batch_batch' is in COMET_LOGGING_METRICS_IGNORE\n",
      "COMET INFO: Ignoring automatic log_metric('batch_size') because 'keras:batch_size' is in COMET_LOGGING_METRICS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, loss:0.1540,  mae:0.2459,  mse:0.1540,  val_loss:0.1378,  val_mae:0.2317,  val_mse:0.1378,  \n",
      "...."
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b7e9cb6fc32f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDECAY_EPOCHS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLR_DECAY_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             logs_dir_name=LOGGING_DIR_NAME, append_wandb=True, comet=True, comet_exp=comet_experiment)\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;31m# ----------------------------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ML_Nuclear_Data\\nucml\\model\\model_building_nn.py\u001b[0m in \u001b[0;36mcompile_and_fit\u001b[1;34m(model, name, x_train, y_train, x_test, y_test, BATCH_SIZE, max_epochs, DECAY_EPOCHS, lr_method, initial_epoch, logs_dir_name, append_wandb, verbose, comet, comet_exp)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs_dir_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs_dir_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend_wandb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mappend_wandb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 initial_epoch=initial_epoch)   \n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\comet_ml\\monkey_patching.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m                     )\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mreturn_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# Call after callbacks once we have the return value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\wandb\\keras\\__init__.py\u001b[0m in \u001b[0;36mnew_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   2044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m     \u001b[0mrow_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m     \u001b[0mrow_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2047\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2048\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\data_mining_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m     \u001b[0mrow_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m     \u001b[0mrow_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2047\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2048\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "for num_layers_to_try in [5]: # np.linspace(1,5, 5, dtype=int): # FOR 1 TO 5 LAYERS   \n",
    "    for num_units in [100]: # [55, 70, 85]:  # FOR 100 TO 500 NEURONS\n",
    "        params = {}\n",
    "        \n",
    "        # ------------------------------------------ TENSORFLOW ----------------------------------------------\n",
    "        # BUILDING MODEL AND LOGGING NUMBER OF LAYERS AND UNITS\n",
    "        model = tf.keras.Sequential() \n",
    "        for num_layers in np.linspace(1, num_layers_to_try, num_layers_to_try, dtype=int):\n",
    "            model.add(tf.keras.layers.Dense(num_units, activation='relu'))\n",
    "            params[\"Layer_{}_Units\".format(num_layers)] = num_units\n",
    "        model.add(tf.keras.layers.Dense(1))\n",
    "        model.build((None, NUM_FEATURES))\n",
    "        # ----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # --------------------------------------- COMET and WANDB --------------------------------------------\n",
    "        # DEFINING NAME OF RUN/EXPERIMENT\n",
    "        RUN_NAME = '{}_Layers_{}_Units_B1_{}'.format(num_layers_to_try, num_units, SCALER_TYPE) \n",
    "        \n",
    "        # CREATING AND ADDING HYPERPARAMETRES TO PARAMS DICT FOR LOGGING\n",
    "        TO_ADD = {'Batch_Size':BATCH_SIZE,\n",
    "                  'Activation':ACTIVATION,\n",
    "                  'Optimizer':OPTIMIZER,\n",
    "                  'LR_Decay_Epochs':LR_DECAY_EPOCHS,\n",
    "                  'Steps_per_Epoch':STEPS_PER_EPOCH,\n",
    "                  \"Layer_{}_Units\".format(num_layers + 1):1,\n",
    "                  \"Number_of_Layers\":num_layers + 1}\n",
    "        params.update(TO_ADD)\n",
    "        # ----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # -------------------------------------------- WANDB -------------------------------------------------\n",
    "        # INITIATING WANDB RUN AND UPDATING CONFIG WITH HYPERPARAMETER VALUES\n",
    "        wandb.init(project=WANDB_PROJECT_NAME, name=RUN_NAME, sync_tensorboard=True, reinit=True, \n",
    "                   group=GROUP_NAME, id=RUN_NAME) # config=TO_ADD)\n",
    "        os.environ['WANDB_NOTEBOOK_NAME'] = '5_NN_EXFOR_v2_neutrons'\n",
    "        wandb.config.update(TO_ADD)\n",
    "        # ----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # -------------------------------------------- COMET -------------------------------------------------\n",
    "        # COMET ML WORKS BY INITIATING EXPERIMENT AND BY LOGGING A DICTIONARY\n",
    "        comet_experiment = Experiment(api_key=\"fJ314gp1hdwdnn3632Z3VCZ2B\",\n",
    "                        project_name=COMMET_PROJECT_NAME, workspace=\"pedrojrv\")\n",
    "        comet_experiment.set_name(RUN_NAME)\n",
    "        comet_experiment.log_parameters(params) # LOGGING HYPERPARAMETERS TO COMET EXPERIMENT\n",
    "        LOGGING_DIR_NAME =  wandb.run.dir  # SETTING DIRECTORY TO SAVE CHECKPOINTS, TENSORBOARD, AND CSV\n",
    "        # ----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # ------------------------------------------ TENSORFLOW ----------------------------------------------\n",
    "        histories[RUN_NAME] = model_tools.compile_and_fit(model, RUN_NAME, \n",
    "            x_train.values, y_train.values, x_test.values, y_test.values, \n",
    "            BATCH_SIZE=BATCH_SIZE, max_epochs=EPOCHS, DECAY_EPOCHS=LR_DECAY_EPOCHS, lr_method=OPTIMIZER, \n",
    "            logs_dir_name=LOGGING_DIR_NAME, append_wandb=True, comet=True, comet_exp=comet_experiment)\n",
    "        # ----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # ------------------------------------------ WANDB ----------------------------------------------\n",
    "        # LOGGING CHLORINE PLOTLY PLOT\n",
    "        fig_to_log_cl = run_chlorine(histories[RUN_NAME].model)\n",
    "        fig_to_log_u = run_uranium(histories[RUN_NAME].model)\n",
    "        wandb.log({'Chlorine_35_NP': fig_to_log_cl})\n",
    "        wandb.log({'Uranium_233_NF': fig_to_log_u})\n",
    "        \n",
    "        # EVERY RUN WANDB CREATES A DIFF.PATCH, WE REMOVE IT TO SAVE TIME WHEN UPLAODING ASSET WITH COMET\n",
    "        os.remove(os.path.join(LOGGING_DIR_NAME, \"diff.patch\"))\n",
    "        # ----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # -------------------------------------------- COMET -------------------------------------------------\n",
    "        # COMET DOES NOT SAVE MODEL OR ANY OTHER DATA FILES, MUST BE LOGGED MANUALLY\n",
    "        # HERE WE LOG THE MODEL, THE TRAINING CSV, THE ENTIRE WANDB FOLDER,\n",
    "        # A PIL VERSION OF THE PLOTLY IMAGE AND THE DATASET VERSION\n",
    "        comet_experiment.log_model(RUN_NAME, os.path.join(wandb.run.dir, \"model-best.h5\")) \n",
    "        comet_experiment.log_asset_folder(LOGGING_DIR_NAME) \n",
    "        comet_experiment.log_table(os.path.join(wandb.run.dir, \"training_metrics.csv\")) \n",
    "        comet_experiment.log_dataset_info(name=\"EXFOR_Basic\", version=\"1\")\n",
    "        \n",
    "        # LOGGING FIGURES TO COMET (DOES NOT ACCEPT PLOTLY)\n",
    "        pil_fig_cl = plot_utils.plotly_fig2pil(fig_to_log_cl)\n",
    "        pil_fig_u = plot_utils.plotly_fig2pil(fig_to_log_u)\n",
    "        comet_experiment.log_image(pil_fig_cl, name=\"Chlorine_35_NP\") # MAPTLOTLIB PYPLOT USING LOG_FIGURE\n",
    "        comet_experiment.log_image(pil_fig_u, name=\"Uranium_233_NF\")\n",
    "        # ----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        wandb.join()\n",
    "        comet_experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T05:30:54.798059Z",
     "start_time": "2020-07-21T05:30:53.133408Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/pedrojrv/ml-nuclear-data/b556a0b45b394bbdb7f8b25cb1135a4d\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     train_batch_loss [3995]   : (0.06486985832452774, 1.3093023300170898)\n",
      "COMET INFO:     train_batch_mae [3995]    : (0.19620899856090546, 0.9269266724586487)\n",
      "COMET INFO:     train_batch_mse [3995]    : (0.11206133663654327, 1.3093023300170898)\n",
      "COMET INFO:     train_epoch_duration [3]  : (51.57799999997951, 54.203999999997905)\n",
      "COMET INFO:     train_loss [3]            : (0.12431211271066338, 0.15403235541660174)\n",
      "COMET INFO:     train_mae [3]             : (0.2176709771156311, 0.2459419220685959)\n",
      "COMET INFO:     train_mse [3]             : (0.12431201338768005, 0.15403242409229279)\n",
      "COMET INFO:     train_val_loss [3]        : (0.12289934111236564, 0.1377505054929432)\n",
      "COMET INFO:     train_val_mae [3]         : (0.21449102461338043, 0.2317296266555786)\n",
      "COMET INFO:     train_val_mse [3]         : (0.12289926409721375, 0.13775047659873962)\n",
      "COMET INFO:     validate_batch_loss [420] : (0.07545582205057144, 0.37322384119033813)\n",
      "COMET INFO:     validate_batch_mae [420]  : (0.20926518738269806, 0.2427273839712143)\n",
      "COMET INFO:     validate_batch_mse [420]  : (0.12263918668031693, 0.18766027688980103)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name                   : 5_Layers_100_Units_B1_std\n",
      "COMET INFO:     train_trainable_params : 46301\n",
      "COMET INFO:   Parameters [count]:\n",
      "COMET INFO:     Activation         : relu\n",
      "COMET INFO:     Adam_amsgrad       : 1\n",
      "COMET INFO:     Adam_beta_1        : 0.9\n",
      "COMET INFO:     Adam_beta_2        : 0.999\n",
      "COMET INFO:     Adam_decay         : 1\n",
      "COMET INFO:     Adam_epsilon       : 1e-07\n",
      "COMET INFO:     Adam_learning_rate : {'class_name': 'InverseTimeDecay', 'config': {'initial_learning_rate': 0.005, 'decay_steps': 125520, 'decay_rate': 0.5, 'staircase': False, 'name': None}}\n",
      "COMET INFO:     Batch_Size         : 300\n",
      "COMET INFO:     LR_Decay_Epochs    : 10\n",
      "COMET INFO:     Layer_1_Units      : 100\n",
      "COMET INFO:     Layer_2_Units      : 100\n",
      "COMET INFO:     Layer_3_Units      : 100\n",
      "COMET INFO:     Layer_4_Units      : 100\n",
      "COMET INFO:     Layer_5_Units      : 100\n",
      "COMET INFO:     Layer_6_Units      : 1\n",
      "COMET INFO:     Number_of_Layers   : 6\n",
      "COMET INFO:     Optimizer [2]      : Adam\n",
      "COMET INFO:     Steps_per_Epoch    : 12552\n",
      "COMET INFO:     train_Adam_name    : Adam\n",
      "COMET INFO:     train_batch_size   : 300\n",
      "COMET INFO:     train_epochs       : 100\n",
      "COMET INFO:     train_samples      : 3765820\n",
      "COMET INFO:     train_steps        : 12552\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                : 1 (10 KB)\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
     ]
    }
   ],
   "source": [
    "wandb.join()\n",
    "comet_experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T22:39:04.127117Z",
     "start_time": "2020-07-16T20:51:49.101256Z"
    }
   },
   "outputs": [],
   "source": [
    "# TAG = \"ASYM500_5_v3\"\n",
    "# params = {}\n",
    "\n",
    "# # ------------------------------------------ TENSORFLOW ----------------------------------------------\n",
    "# # BUILDING MODEL AND LOGGING NUMBER OF LAYERS AND UNITS\n",
    "# params[\"Layer_1_Units\"] = 500\n",
    "# params[\"Layer_2_Units\"] = 400\n",
    "# params[\"Layer_3_Units\"] = 300\n",
    "# params[\"Layer_4_Units\"] = 200\n",
    "# params[\"Layer_5_Units\"] = 100\n",
    "# params[\"Layer_6_Units\"] = 50\n",
    "# params[\"Layer_7_Units\"] = 25\n",
    "# params[\"Layer_8_Units\"] = 15\n",
    "# params[\"Layer_9_Units\"] = 10\n",
    "# params[\"Layer_10_Units\"] = 5\n",
    "# params[\"Layer_11_Units\"] = 1\n",
    "\n",
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(params[\"Layer_1_Units\"], activation=ACTIVATION), \n",
    "#     tf.keras.layers.Dense(params[\"Layer_2_Units\"], activation=ACTIVATION),\n",
    "#     tf.keras.layers.Dense(params[\"Layer_3_Units\"], activation=ACTIVATION), \n",
    "#     tf.keras.layers.Dense(params[\"Layer_4_Units\"], activation=ACTIVATION),\n",
    "#     tf.keras.layers.Dense(params[\"Layer_5_Units\"], activation=ACTIVATION),\n",
    "#     tf.keras.layers.Dense(params[\"Layer_6_Units\"], activation=ACTIVATION),\n",
    "#     tf.keras.layers.Dense(params[\"Layer_7_Units\"], activation=ACTIVATION), \n",
    "#     tf.keras.layers.Dense(params[\"Layer_8_Units\"], activation=ACTIVATION), \n",
    "#     tf.keras.layers.Dense(params[\"Layer_9_Units\"], activation=ACTIVATION), \n",
    "#     tf.keras.layers.Dense(params[\"Layer_10_Units\"], activation=ACTIVATION), \n",
    "#     tf.keras.layers.Dense(params[\"Layer_11_Units\"])])\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # --------------------------------------- COMET and WANDB --------------------------------------------\n",
    "# # DEFINING NAME OF RUN/EXPERIMENT\n",
    "# RUN_NAME = '{}_Layers_{}_B1_{}'.format(len(params)-1, TAG, SCALER_TYPE) \n",
    "\n",
    "# # CREATING AND ADDING HYPERPARAMETRES TO PARAMS DICT FOR LOGGING\n",
    "# TO_ADD = {'Batch_Size':BATCH_SIZE,\n",
    "#           'Activation':ACTIVATION,\n",
    "#           'Optimizer':OPTIMIZER,\n",
    "#           'LR_Decay_Epochs':LR_DECAY_EPOCHS,\n",
    "#           'Steps_per_Epoch':STEPS_PER_EPOCH,\n",
    "#           \"Number_of_Layers\":len(params)}\n",
    "# params.update(TO_ADD)\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # -------------------------------------------- WANDB -------------------------------------------------\n",
    "# # INITIATING WANDB RUN AND UPDATING CONFIG WITH HYPERPARAMETER VALUES\n",
    "# wandb.init(project=WANDB_PROJECT_NAME, name=RUN_NAME, sync_tensorboard=True, reinit=True, \n",
    "#            group=GROUP_NAME, id=RUN_NAME) # config=TO_ADD)\n",
    "# os.environ['WANDB_NOTEBOOK_NAME'] = '5_NN_EXFOR_v2_neutrons'\n",
    "# wandb.config.update(TO_ADD)\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # -------------------------------------------- COMET -------------------------------------------------\n",
    "# # COMET ML WORKS BY INITIATING EXPERIMENT AND BY LOGGING A DICTIONARY\n",
    "# comet_experiment = Experiment(api_key=\"fJ314gp1hdwdnn3632Z3VCZ2B\",\n",
    "#                 project_name=COMMET_PROJECT_NAME, workspace=\"pedrojrv\")\n",
    "# comet_experiment.set_name(RUN_NAME)\n",
    "# comet_experiment.log_parameters(params) # LOGGING HYPERPARAMETERS TO COMET EXPERIMENT\n",
    "# LOGGING_DIR_NAME =  wandb.run.dir  # SETTING DIRECTORY TO SAVE CHECKPOINTS, TENSORBOARD, AND CSV\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # ------------------------------------------ TENSORFLOW ----------------------------------------------\n",
    "# histories[RUN_NAME] = model_tools.compile_and_fit(model, RUN_NAME, \n",
    "#     x_train.values, y_train.values, x_test.values, y_test.values, \n",
    "#     BATCH_SIZE=BATCH_SIZE, max_epochs=EPOCHS, DECAY_EPOCHS=LR_DECAY_EPOCHS, lr_method=OPTIMIZER, \n",
    "#     logs_dir_name=LOGGING_DIR_NAME, append_wandb=True, comet=True, comet_exp=comet_experiment)\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # ------------------------------------------ WANDB ----------------------------------------------\n",
    "# # LOGGING CHLORINE PLOTLY PLOT\n",
    "# fig_to_log_cl = run_chlorine(histories[RUN_NAME].model)\n",
    "# fig_to_log_u = run_uranium(histories[RUN_NAME].model)\n",
    "# wandb.log({'Chlorine_35_NP': fig_to_log_cl})\n",
    "# wandb.log({'Uranium_233_NF': fig_to_log_u})\n",
    "\n",
    "# # EVERY RUN WANDB CREATES A DIFF.PATCH, WE REMOVE IT TO SAVE TIME WHEN UPLAODING ASSET WITH COMET\n",
    "# os.remove(os.path.join(LOGGING_DIR_NAME, \"diff.patch\"))\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# # -------------------------------------------- COMET -------------------------------------------------\n",
    "# # COMET DOES NOT SAVE MODEL OR ANY OTHER DATA FILES, MUST BE LOGGED MANUALLY\n",
    "# # HERE WE LOG THE MODEL, THE TRAINING CSV, THE ENTIRE WANDB FOLDER,\n",
    "# # A PIL VERSION OF THE PLOTLY IMAGE AND THE DATASET VERSION\n",
    "# comet_experiment.log_model(RUN_NAME, os.path.join(wandb.run.dir, \"model-best.h5\")) \n",
    "# comet_experiment.log_asset_folder(LOGGING_DIR_NAME) \n",
    "# comet_experiment.log_table(os.path.join(wandb.run.dir, \"training_metrics.csv\")) \n",
    "# comet_experiment.log_dataset_info(name=\"EXFOR_Basic\", version=\"1\")\n",
    "\n",
    "# # LOGGING FIGURES TO COMET (DOES NOT ACCEPT PLOTLY)\n",
    "# pil_fig_cl = plot_utils.plotly_fig2pil(fig_to_log_cl)\n",
    "# pil_fig_u = plot_utils.plotly_fig2pil(fig_to_log_u)\n",
    "# comet_experiment.log_image(pil_fig_cl, name=\"Chlorine_35_NP\") # MAPTLOTLIB PYPLOT USING LOG_FIGURE\n",
    "# comet_experiment.log_image(pil_fig_u, name=\"Uranium_233_NF\")\n",
    "# # ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# wandb.join()\n",
    "# comet_experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T22:39:04.150621Z",
     "start_time": "2020-07-16T22:39:04.137618Z"
    }
   },
   "outputs": [],
   "source": [
    "# def run_chlorine(model):\n",
    "#     cl_kwargs =  {\"Z\":17, \"A\":35, \"MT\":\"MT_103\", \"clf_type\":\"tf\", \"scaler\":scaler, \"to_scale\":to_scale, \"html\":False,\n",
    "#                   \"e_array\":\"ace\", \"log\":True, \"show\":False, \"render\":False, \"save\":False}\n",
    "#     results_cl = exfor_utils.predicting_nuclear_xs_v2(df, clf=model, new_data=new_cl_data, get_endf=True, **cl_kwargs)\n",
    "#     fig = plot_utils.plotly_ml_results(results_cl, show=True)\n",
    "#     return fig\n",
    "\n",
    "# best_model = tf.keras.models.load_model('./wandb/run-20200705_013609-7_Layers_200_Units_B1/model-best.h5')\n",
    "# best_model_comet = tf.keras.models.load_model('./wandb/run-20200705_013609-7_Layers_200_Units_B1/checkpoints/best_model.hdf5')\n",
    "\n",
    "# fig_to_log_cl = run_chlorine(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cl_kwargs =  {\"Z\":17, \"A\":35, \"MT\":\"MT_103\", \"clf_type\":\"tf\", \"scaler\":scaler, \"to_scale\":to_scale, \"html\":False,\n",
    "#               \"e_array\":\"ace\", \"log\":True, \"show\":True, \"render\":True, \"save\":False}\n",
    "# results_cl = exfor_utils.predicting_nuclear_xs_v2(df, clf=best_model, new_data=new_cl_data, get_endf=True, **cl_kwargs)\n",
    "\n",
    "# order = {\n",
    "#     \"3\":\"endf\", \n",
    "#     \"1\":\"exfor_ml_original\", \n",
    "#     \"2\":\"exfor_ml\", \n",
    "#     \"4\":\"exfor_new\"}\n",
    "\n",
    "# u_kwargs =  {\"Z\":92, \"A\":233, \"MT\":\"MT_18\", \"clf_type\":\"tf\", \"scaler\":scaler, \"to_scale\":to_scale, \"html\":False,\n",
    "#               \"e_array\":\"ace\", \"log\":True, \"show\":True, \"render\":True, \"save\":False}\n",
    "# results_u = exfor_utils.predicting_nuclear_xs_v2(df, clf=best_model, get_endf=True, order_dict=order, **u_kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
