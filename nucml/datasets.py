import os
from pathlib import Path
from joblib import dump, load
import logging
import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import train_test_split

logging.basicConfig(level=logging.INFO)

################################################################################
# DEFINING NECESSARY PATHS TO FIND DATASETS 
################################################################################
# ml_nuclear_path = "/Users/pedrovicentevaldez/Desktop/ML_Nuclear_Data/"
ame_dir_path = os.path.abspath("../AME/")


# TO DO: MAKE PATH ABSOLUTE FOR WINDOWS AND MAC
def load_ame(directory=ame_dir_path, natural=True, nan=False):
    """Loads the Atomic Mass Evaluation 2016 data generated by NucML using the parsing utilities.

    Args:
        directory (str): string representing the path to the directory where the AME files are stored.
        natural (bool): if True, the AME data will be loaded along with rows representing natural data.
        nan (bool): Only applicable when natural=True. If True, the original AME data will be loaded. 
            If False, then the linearly imputed data is loaded.

    Returns:
        DataFrame: a pandas dataframe cantaining the AME data.

    """

    if natural:
        if nan:
            ame_file_path = os.path.join(directory, "AME_Natural_Properties_w_NaN.csv")
        else:
            ame_file_path = os.path.join(directory, "AME_Natural_Properties_no_NaN.csv")
    else:
        ame_file_path = os.path.join(directory, "AME_all_merged.csv")

    if os.path.exists(ame_file_path):
        logging.info("AME: Reading and loading Atomic Mass Evaluation files from: \n {}".format(ame_file_path))
        ame = pd.read_csv(ame_file_path)
        return ame
    else:
        logging.error("AME: Requested file does not exists. Check that it exists on the given directory path. \
            If it does not exists then it probably hasn't been generated.")
        return None

def load_ame_mass16(directory=ame_dir_path):
    """Loads the Atomic Mass Evaluation 2016 Mass 16 data generated by NucML using the parsing utilities.

    Args:
        directory (str): string representing the path to the directory where the Mass 16 AME file is stored.

    Returns:
        DataFrame: a pandas dataframe cantaining the Mass 16 AME data.

    """

    ame_file_path = os.path.join(directory, "AME_mass16.csv")
    if os.path.exists(ame_file_path):
        logging.info("AME MASS16: Reading and loading the Atomic Mass Evaluation Mass 16 file from: \n {}".format(ame_file_path))
        ame = pd.read_csv(ame_file_path)
        return ame
    else:
        logging.error("AME MASS16: Requested file does not exists. Check that it exists on the given directory path. \
            If it does not exists then it probably hasn't been generated.")
        return None

def load_ame_rct1(directory=ame_dir_path):
    """Loads the Atomic Mass Evaluation 2016 RCT1 data generated by NucML using the parsing utilities.

    Args:
        directory (str): string representing the path to the directory where the RCT1 AME file is stored.

    Returns:
        DataFrame: a pandas dataframe cantaining the Mass 16 AME data.

    """

    ame_file_path = os.path.join(directory, "AME_rct1.csv")
    if os.path.exists(ame_file_path):
        logging.info("AME RCT1: Reading and loading the Atomic Mass Evaluation RCT1 file from: \n {}".format(ame_file_path))
        ame = pd.read_csv(ame_file_path)
        return ame
    else:
        logging.error("AME RCT1: Requested file does not exists. Check that it exists on the given directory path. \
            If it does not exists then it probably hasn't been generated.")
        return None


def load_ame_rct2(directory=ame_dir_path):
    """Loads the Atomic Mass Evaluation 2016 RCT2 data generated by NucML using the parsing utilities.

    Args:
        directory (str): string representing the path to the directory where the RCT2 AME file is stored.

    Returns:
        DataFrame: a pandas dataframe cantaining the RCT2 AME data.

    """

    ame_file_path = os.path.join(directory, "AME_rct2.csv")
    if os.path.exists(ame_file_path):
        logging.info("AME RCT2: Reading and loading the Atomic Mass Evaluation RCT1 file from: \n {}".format(ame_file_path))
        ame = pd.read_csv(ame_file_path)
        return ame
    else:
        logging.error("AME RCT2: Requested file does not exists. Check that it exists on the given directory path. \
            If it does not exists then it probably hasn't been generated.")
        return None


def load_endf(ELAAA, MT, mode="neutrons", mev_to_ev=True, mb_to_b=True, log=False, drop_u=True):
    """Reads Evaluated Nuclear Data File for a specific element and reaction channel. It is important
    to inspect the returned data since it queries an external database which extracted data from ENDF 
    using a particular script. It has been found that some particular reactions are not included.

    Args:
        elementELAAA (str): element to query. Must be in ELAAA format (i.e. U233, Cl35). An error will be 
            raised if the arguments are not formated correctly.
        MT (str): reaction channel to query. Must be in MT### format (i.e. MT018, MT101)
        mev_to_ev (bool): if True, it converts energy from meV to eV.
        mb_to_b (bool): if True, it converts the cross sections from mb to b.

    Returns:
        DataFrame: (Energy, Cross Section) Pandas DataFrame.
        None: if file does not exist. 

    """
    path = os.path.abspath("../ML_Data/ENDF_" + mode + "/" + ELAAA + "/endfb8.0/tables/xs/n-" + ELAAA + "-" + MT + ".endfb8.0")
    file = Path(path)
    if file.is_file():
        logging.info("ENDF: Extracting data from {}".format(path))
        # uranium is in MeV, we need eV
        endf = pd.read_csv(path, skiprows=5, header=None, names=["Energy", "Data", "dDataLow", "dDataUpp"], delim_whitespace=True)
        if mev_to_ev:
            logging.info("ENDF: Converting MeV to eV...")
            endf["Energy"] = endf["Energy"]*1E6
        if mb_to_b:
            logging.info("ENDF: Converting mb to b...")
            endf["Data"] = endf["Data"]*0.001
        if log:
            endf["Energy"] = np.log10(endf["Energy"])
            endf["Data"] = np.log10(endf["Data"])
            endf["dDataLow"] = np.log10(endf["dDataLow"])
            endf["dDataUpp"] = np.log10(endf["dDataUpp"])
        if drop_u:
            if "dData" in list(endf.columns):
                endf = endf.drop(columns=["dDataLow"])
            if "dData2" in list(endf.columns):
                endf = endf.drop(columns=["dDataUpp"])
        logging.info("ENDF: Finished. ENDF data contains {} datapoints.".format(endf.shape[0]))
        return endf
    else:
        logging.info("ENDF: File does not exists. Check path.")
        return None

supported_modes = ["neutrons", "protons", "alphas", "deuterons", "gammas", "helions", "all"]
def load_exfor(log=False, low_en=True, basic=-1, num=False, frac=0.1, mode="neutrons", scaling_type="pt", scaler_dir=None):
    """[summary]

    Args:
        log (bool, optional): [description]. Defaults to False.
        low_en (bool, optional): [description]. Defaults to True.
        basic (int, optional): [description]. Defaults to -1.
        num (bool, optional): [description]. Defaults to False.
        frac (float, optional): [description]. Defaults to 0.1.
        mode (str, optional): [description]. Defaults to "neutrons".
        scaling_type (str, optional): [description]. Defaults to "pt".
        scaler_dir ([type], optional): [description]. Defaults to None.

    Returns:
        [type]: [description]
    """
    
    ######## SETTING UP VARIABLES FOR DATA EXTRACTION ##########
    mode = mode.lower()
    if mode not in supported_modes:
        return logging.error("Specified MODE not supported. Supporte modes include: {}".format(' '.join([str(v) for v in supported_modes])))
    logging.info(" MODE: {}".format(mode))
    logging.info(" LOW ENERGY: {}".format(low_en))
    logging.info(" LOG: {}".format(log))
    logging.info(" BASIC: {}".format(basic))
    if num:
        logging.info(" SCALER: {}".format(scaling_type.upper()))
    datapath = os.path.abspath("../ML_Data/EXFOR_" + mode + "/EXFOR_" + mode + "_MF3_AME_no_NaNRaw.csv")
    if os.path.exists(datapath):
        logging.info("Reading data from {}".format(datapath))
    else:
        return logging.error("CSV file does not exists. Check path.")


    df = pd.read_csv(datapath, dtype=dtype_exfor).dropna()
    df = df[~((df.Reaction_Notation.str.contains("WTR")) | (df.Title.str.contains("DERIV")) | (df.Energy == 0) | (df.Data == 0))]
    if low_en:
        df = df[df.Energy < 2.0E7]
    if log:
        df["Energy"] = np.log10(df["Energy"])
        df["Data"] = np.log10(df["Data"])
    if basic == 0:
        basic_cols = ["Energy", "dEnergy", "Data", "dData", "MT", "Target_Protons", "Frame",
                      "Target_Neutrons", "Target_Mass_Number", "Target_Flag"]
        df = df[basic_cols]
    elif basic == 1:
        # 'Target_S(2p)' THIS IS AN ISSUE WITH YEO TRANSFORMER FOR SOME REASON
        basic_cols = ["Energy", "dEnergy", "Data", "dData", "MT", "Target_Protons", "Frame",
                      "Target_Neutrons", "Target_Mass_Number", "Target_Flag", 'Target_Radius', 
                      'Target_Neut_Rad_Ratio', 'Target_Mass_Excess', 'Target_Binding_Energy', 
                      'Target_B_Decay_Energy', 'Target_Atomic_Mass_Micro', 'Target_S(2n)', 
                      'Target_S(n)', 'Target_S(p)']
        df = df[basic_cols]  
    print("Data read into dataframe with shape: ", df.shape)
    if num:
        print("Dropping unnecessary features and one-hot encoding categorical columns...")
        if basic == 0 or basic == 1:
            columns_drop = ["dData", "dEnergy"]
            cat_cols = ["MT", "Frame", "Target_Flag"]
        else:
            columns_drop = ["Reaction_Notation", "Title", "Institute", "Date", "Reference", "Out", "Target_Element",
                            "Target_Element_w_A", "Compound_EL", "EntrySubP", "EXFOR_Status", "Year", "dData", "dEnergy"]
            cat_cols = ["Target_Meta_State", "MT", "I78", "Product_Meta_State", "Frame", "Target_Flag", "Target_Origin", "Compound_Origin"]
        df.drop(columns=columns_drop, inplace=True)
        # We need to keep track of columns to normalize excluding categorical data.
        norm_columns = len(df.columns) - len(cat_cols) - 1
        df = pd.concat([df, pd.get_dummies(df[cat_cols])], axis=1).drop(columns=cat_cols)
        print("Splitting dataset into training and testing...")
        x_train, x_test, y_train, y_test = train_test_split(df.drop(["Data"], axis=1), df["Data"], test_size=frac)
        print("Normalizing dataset...")
        to_scale = list(x_train.columns)[:norm_columns]
        # to_scale.remove("Energy")
        if scaler_dir is not None:
            print("Using previously saved scaler.")
            scaler = load(open(scaler_dir, 'rb'))
        else:
            print("Fitting new scaler.")
            if scaling_type == "pt":
                scaler = preprocessing.PowerTransformer().fit(x_train[to_scale])
            elif scaling_type == "std":
                scaler = preprocessing.StandardScaler().fit(x_train[to_scale])
            elif scaling_type == "minmax":
                scaler = preprocessing.MinMaxScaler().fit(x_train[to_scale])
        x_train[to_scale] = scaler.transform(x_train[to_scale])
        x_test[to_scale] = scaler.transform(x_test[to_scale])
        print("Finished. Resulting dataset has shape ", df.shape,
            "\nTraining and Testing dataset shapes are {} and {} respesctively.".format(x_train.shape, x_test.shape))
        return df, x_train, x_test, y_train, y_test, to_scale, scaler
    else:
        print("Finished. Resulting dataset has shape ", df.shape)
        return df

# df.dtypes.apply(lambda x: x.name).to_dict()
dtype_exfor = {'Target_Meta_State': 'category',
            'MT': 'category',
            'Energy': 'float64',
            'dEnergy': 'float64',
            'Data': 'float64',
            'dData': 'float64',
            'ELV/HL': 'float64',
            'dELV/HL': 'float64',
            'I78': 'category',
            'EntrySubP': 'str',
            'Target_Protons': 'int32',
            'Product_Meta_State': 'category',
            'EXFOR_Status': 'category',
            'Frame': 'category',
            'Reaction_Notation': 'category',
            'Title': 'category',
            'Year': 'int32',
            'Institute': 'category',
            'Date': 'int32',
            'Reference': 'category',
            'Out': 'category',
            'Target_Neutrons': 'int32',
            'Target_Mass_Number': 'int32',
            'Target_Element': 'category',
            'Target_Flag': 'category',
            'Target_Element_w_A': 'category',
            'Target_Radius': 'float64',
            'Target_Neut_Rad_Ratio': 'float64',
            'Target_Origin': 'category',
            'Target_Mass_Excess': 'float64',
            'Target_dMass_Excess': 'float64',
            'Target_Binding_Energy': 'float64',
            'Target_dBinding_Energy': 'float64',
            'Target_B_Decay_Energy': 'float64',
            'Target_dB_Decay_Energy': 'float64',
            'Target_Atomic_Mass_Micro': 'float64',
            'Target_dAtomic_Mass_Micro': 'float64',
            'Target_S(2n)': 'float64',
            'Target_dS(2n)': 'float64',
            'Target_S(2p)': 'float64',
            'Target_dS(2p)': 'float64',
            'Target_S(n)': 'float64',
            'Target_dS(n)': 'float64',
            'Target_S(p)': 'float64',
            'Target_dS(p)': 'float64',
            'Compound_Neutrons': 'int32',
            'Compound_Mass_Number': 'int32',
            'Compound_Protons': 'int32',
            'Compound_EL': 'category',
            'Compound_Origin': 'category',
            'Compound_Mass_Excess': 'float64',
            'Compound_dMass_Excess': 'float64',
            'Compound_Binding_Energy': 'float64',
            'Compound_dBinding_Energy': 'float64',
            'Compound_B_Decay_Energy': 'float64',
            'Compound_dB_Decay_Energy': 'float64',
            'Compound_Atomic_Mass_Micro': 'float64',
            'Compound_dAtomic_Mass_Micro': 'float64',
            'Compound_S(2n)': 'float64',
            'Compound_dS(2n)': 'float64',
            'Compound_S(2p)': 'float64',
            'Compound_dS(2p)': 'float64',
            'Compound_S(n)': 'float64',
            'Compound_dS(n)': 'float64',
            'Compound_S(p)': 'float64',
            'Compound_dS(p)': 'float64'}
